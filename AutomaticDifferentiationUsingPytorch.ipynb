{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutomaticDifferentiationUsingPytorch.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/periwinklemctartins/Coronavirus--Propogation-Simulation/blob/master/AutomaticDifferentiationUsingPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO2bSPsWNlqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib           \n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Connections between Canadian Provinces\n",
        "A = torch.tensor([[1,     1,     1,     0,     0,     0,     0,     0,     1,     0,     1,     1,     1],\n",
        "                  [1,     1,     1,     0,     0,     1,     0,     0,     1,     0,     1,     1,     0],\n",
        "                  [1,     1,     1,     0,     0,     1,     0,     1,     1,     0,     1,     1,     0],\n",
        "                  [0,     0,     0,     1,     1,     0,     0,     0,     1,     1,     1,     0,     0],\n",
        "                  [0,     0,     0,     1,     1,     0,     1,     0,     1,     1,     1,     0,     0],\n",
        "                  [0,     1,     1,     0,     0,     1,     0,     1,     1,     0,     1,     1,     1],\n",
        "                  [0,     0,     0,     0,     1,     0,     1,     0,     1,     1,     1,     0,     0],\n",
        "                  [0,     0,     1,     0,     0,     1,     0,     1,     1,     0,     1,     1,     1],\n",
        "                  [1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
        "                  [0,     0,     0,     1,     1,     0,     1,     0,     1,     1,     1,     0,     0],\n",
        "                  [1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
        "                  [1,     1,     1,     0,     0,     1,     0,     1,     1,     0,     1,     1,     0],\n",
        "                  [1,     0,     0,     0,     0,     1,     0,     1,     1,     0,     1,     0,     1]]);\n",
        "\n",
        "#Number of connections each province has                  \n",
        "L = torch.tensor([[6,    -1,    -1,     0,     0,     0,     0,     0,    -1,     0,    -1,    -1,    -1], \n",
        "                  [-1,    6,    -1,     0,     0,    -1,     0,     0,    -1,     0,    -1,    -1,     0],\n",
        "                  [-1,    1,     7,     0,     0,    -1,     0,    -1,    -1,     0,    -1,    -1,     0],\n",
        "                  [0,     0,     0,     4,    -1,     0,     0,     0,    -1,    -1,    -1,     0,     0],\n",
        "                  [0,     0,     0,    -1,     5,     0,    -1,     0,    -1,    -1,    -1,     0,     0],\n",
        "                  [0,    -1,    -1,     0,     0,     7,     0,    -1,    -1,     0,    -1,    -1,    -1],\n",
        "                  [0,     0,     0,     0,    -1,     0,     4,     0,    -1,    -1,    -1,     0,     0],\n",
        "                  [0,     0,    -1,     0,     0,    -1,     0,     6,    -1,     0,    -1,    -1,    -1],\n",
        "                  [-1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    12,    -1,    -1,    -1,   -1],\n",
        "                  [0,     0,     0,    -1,    -1,     0,    -1,     0,    -1,     5,    -1,     0,     0],\n",
        "                  [-1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    12,    -1,   -1],\n",
        "                  [-1,    -1,    -1,     0,     0,    -1,     0,    -1,    -1,     0,    -1,     7,    0],\n",
        "                  [-1,     0,     0,     0,     0,    -1,     0,    -1,    -1,     0,    -1,     0,    5]]);\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Ls36tkNqqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SEImodel(theta,S,E,I):\n",
        "    alpha = theta[0]\n",
        "    beta  = theta[1]\n",
        "    gamma = theta[2]\n",
        "    mu    = theta[3]\n",
        "    kE    = theta[4]\n",
        "    kS    = theta[5]\n",
        "    kI    = theta[6]\n",
        "    \n",
        "\n",
        "    dSdt  = -kS*L[n,n]*S - beta*E*S - gamma*I*S                 # dS/dt\n",
        "    dEdt  = -kE*L[n,n]*E + beta*E*S  + gamma*I*S - alpha*E      # dE/dt\n",
        "    dIdt  = -kI*L[n,n]*I + alpha*E - mu*I                       # dI/dt\n",
        "    \n",
        "    return dSdt, dEdt, dIdt\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjBsWqAWNtIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def integrateSEI(theta,S0,E0,I0,dt,nt):\n",
        "    \n",
        "    # vectors to save the results over time\n",
        "    Sout = torch.zeros(nt+1); Sout[0] = S0\n",
        "    Eout = torch.zeros(nt+1); Eout[0] = E0\n",
        "    Iout = torch.zeros(nt+1); Iout[0] = I0\n",
        "    \n",
        "    S = S0; E = E0; I = I0\n",
        "    for i in range(nt):\n",
        "        dSdt, dEdt, dIdt = SEImodel(theta,S,E,I)\n",
        " \n",
        "\n",
        "        S += dt*dSdt\n",
        "        E += dt*dEdt\n",
        "        I += dt*dIdt\n",
        "\n",
        "        Sout[i+1] = S\n",
        "        Eout[i+1] = E\n",
        "        Iout[i+1] = I\n",
        "       \n",
        "    if I >= 0.05:\n",
        "      print(S,E,I)\n",
        "      return Sout, Eout, Iout\n",
        "       \n",
        "    return Sout, Eout, Iout\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwTfHyfHNvYK",
        "colab_type": "code",
        "outputId": "51c3bcf1-6103-43c5-d2f2-bcc6889a9a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "#BC Data as of March 22 2020\n",
        "PopulationBC = 5071000  #Census Canada\n",
        "Recovered = 0          #Deceased -> it is impossible to tell if people who have recovered have returned to being infected\n",
        "Infected = 424 - Recovered    #https://www150.statcan.gc.ca/n1/daily-quotidien/200428/dq200428a-eng.htm\n",
        "Succeptible = PopulationBC - Infected\n",
        "#Exposed -> true value is unknown -> assume 15% of those who are exposed are not sick\n",
        "\n",
        "xmin = 0; xmax = 2.5;\n",
        "ymin = 0; ymax = .01;\n",
        "\n",
        "#March 28th highest amount of new infected, data can be found here https://experience.arcgis.com/experience/a6f23959a8b14bfa989e3cda29297ded\n",
        "#Did not use data from https://www.canada.ca/en/public-health/services/diseases/2019-novel-coronavirus-infection.html because it was less precise than the provincial one shown above\n",
        "\n",
        "S0 = Succeptible/PopulationBC\n",
        "E0 = 0.014\n",
        "I0 = Infected/PopulationBC\n",
        "\n",
        "# Set the duration for the simulation\n",
        "dt = 0.05; nt = 100\n",
        "\n",
        "# We pick the parameters as follows\n",
        "alpha = .77       #rate of exposed people that get sick\n",
        "beta  = .5       #rate of interaction of exposed and susceptible\n",
        "gamma = .1       #rate of interaction infected and susceptible\n",
        "mu    = 0.015       #rate of pepole who get resistence or die\n",
        "kE    = 0.6       #Exposed people that move around\n",
        "kS    = 0.8       #Susceptible people that move around\n",
        "kI    = 0.2     #Sick people that move around (Diffusion of sick people)\n",
        "theta = torch.tensor([alpha, beta, gamma, mu, kE, kS, kI])\n",
        "\n",
        "P = ['AB', 'BC', 'MB', 'NB', 'NL', 'NT', 'NS', 'NU', 'ON', 'PE', 'QC', 'SK', 'YT']\n",
        "for n in range(1):\n",
        "\n",
        "  S, E, I = integrateSEI(theta,S0,E0,I0,dt,nt)\n",
        "\n",
        "  t = np.arange(nt+1)*dt\n",
        "  title = 'maximum of infected people % on a given day', P[1], torch.max(I).item()\n",
        "  plt.figure(1)\n",
        "  plt.title(title)\n",
        "  plt.plot(t,S,t,E,t,I)\n",
        "\n",
        "  axes = plt.gca()\n",
        "  axes.set_xlim([xmin,xmax])\n",
        "  axes.set_ylim([ymin,ymax])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiE0bJG9R_rq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ForwardEuler(alpha,beta,gamma,mu,kE,kS,kI,S0,E0,I0,dt,nt):  #Looks to be similar to integrateSEI\n",
        "    \n",
        "    S = torch.zeros(nt+1)\n",
        "    E = torch.zeros(nt+1)\n",
        "    I = torch.zeros(nt+1)\n",
        "    S[0] = S0; E[0] = E0; I[0] = I0\n",
        "    for i in range(nt):\n",
        "        F = Model(alpha,beta,gamma,mu,kE,kS,kI,S[i],E[i],I[i])\n",
        "        S[i+1] = S[i] + dt*F[0]\n",
        "        E[i+1] = E[i] + dt*F[1]\n",
        "        I[i+1] = I[i] + dt*F[2]\n",
        "        \n",
        "    return S, E, I"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_o1vVs0KXhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Model(alpha,beta,gamma,mu,kE,kS,kI,S,E,I):  #Looks to be similar to SEImodel\n",
        "    \n",
        "    F = torch.zeros(3)\n",
        "    F[0]  = -kS*L[n,n]*S - beta*E*S - gamma*I*S                 # dS/dt\n",
        "    F[1]  = -kE*L[n,n]*E + beta*E*S  + gamma*I*S - alpha*E      # dE/dt\n",
        "    F[2]  = -kI*L[n,n]*I + alpha*E - mu*I                       # dI/dt\n",
        "    \n",
        "    return F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wo_V9z6RDLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(alpha,beta,gamma,mu,kE,kS,kI,Sobs,Eobs,Iobs,dt,nt):\n",
        "    \n",
        "    Scomp, Ecomp, Icomp = ForwardEuler(alpha,beta,gamma,mu,kE,kS,kI,S0,E0,I0,dt,nt) #comp is computed from code with a chosen beta, gamma \n",
        "    phi = torch.sum((Scomp-Sobs)**2) + torch.sum((Ecomp-Eobs)**2) + torch.sum((Icomp-Iobs)**2) #if comp and obs is the same then phi goes to zero\n",
        "    \n",
        "    return phi\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOg5IddeeQyu",
        "colab_type": "code",
        "outputId": "da464f7e-fd35-4bc4-e48e-27278919bc4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(loss(alpha,beta,gamma,mu,kE,kS,kI,S0,E0,I0,dt,nt))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(95.0419)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB8wL6-PQdZn",
        "colab_type": "code",
        "outputId": "48356e6e-5d2a-444a-cadc-09436f6d01e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "t = np.arange(nt+1); t = t*dt\n",
        "\n",
        "# Add noise to the data\n",
        "ndata = S.shape\n",
        "nS = torch.randn(ndata[0])*0.02\n",
        "nE = torch.randn(ndata[0])*0.02\n",
        "nI = torch.randn(ndata[0])*0.02\n",
        "\n",
        "Sobs = S+nS; Eobs = E+nE; Iobs = I+nI  #observed plus noise\n",
        "\n",
        "# This is what we observe\n",
        "plt.plot(t,Sobs) #make noise smaller to make the curves nicer\n",
        "plt.plot(t,Eobs)\n",
        "plt.plot(t,Iobs) \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc702c632b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFJ_8hvEwgVP",
        "colab_type": "code",
        "outputId": "daf96dfc-0e80-4216-bb4b-15e11865b303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "theta"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7700, 0.5000, 0.1000, 0.0150, 0.6000, 0.8000, 0.2000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUSPEPEs2aZy",
        "colab_type": "code",
        "outputId": "e1d5d993-bcad-4b1d-dd95-f7cbbd15e8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Now we compute gradients\n",
        "x = torch.tensor(theta, requires_grad=True)\n",
        "Sg, Eg, Ig = SEImodel(x,S0,E0,I0)\n",
        "\n",
        "Sg.backward()\n",
        "Eg.backward()\n",
        "Ig.backward()\n",
        "\n",
        "grad = x.grad\n",
        "gradEg = x.grad\n",
        "gradIg = x.grad\n",
        "\n",
        "print(gradSg)\n",
        "print(gradEg)\n",
        "print(gradIg)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3613e-05, -8.4000e-02,\n",
            "        -5.9995e+00, -5.0168e-04])\n",
            "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3613e-05, -8.4000e-02,\n",
            "        -5.9995e+00, -5.0168e-04])\n",
            "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3613e-05, -8.4000e-02,\n",
            "        -5.9995e+00, -5.0168e-04])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTayC-tisB12",
        "colab_type": "code",
        "outputId": "a1a19f84-4f40-4e59-8d76-e9c04dd3ac5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\n",
        "alpha = torch.rand(1, requires_grad=True)\n",
        "beta  = torch.rand(1, requires_grad=True)\n",
        "gamma = torch.rand(1, requires_grad=True)\n",
        "#mu    = torch.rand(1, requires_grad=True)\n",
        "kE    = torch.rand(1, requires_grad=True)\n",
        "kS    = torch.rand(1, requires_grad=True)\n",
        "kI    = torch.rand(1, requires_grad=True)\n",
        "\n",
        "print(alpha)\n",
        "print(beta)\n",
        "print(gamma)\n",
        "#print(mu)\n",
        "print(kE)\n",
        "print(kS)\n",
        "print(kI)\n",
        "\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.8462], requires_grad=True)\n",
            "tensor([0.3739], requires_grad=True)\n",
            "tensor([0.9314], requires_grad=True)\n",
            "tensor([0.3164], requires_grad=True)\n",
            "tensor([0.1076], requires_grad=True)\n",
            "tensor([0.5403], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyoX4n4StIPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dSdt, dEdt, dIdt = f(alpha,beta,gamma,mu,kE,kS,kI,S00,E00,I00)\n",
        "\n",
        "dSdt.backward()\n",
        "dEdt.backward()\n",
        "dIdt.backward()\n",
        "\n",
        "dy_dalpha = alpha.grad\n",
        "dy_dbeta = beta.grad\n",
        "dy_dgamma = gamma.grad\n",
        "#dy_dmu = mu.grad\n",
        "dy_dkE = kE.grad\n",
        "dy_dkS = kS.grad\n",
        "dy_dkI = kI.grad\n",
        "\n",
        "print(dy_dalpha)\n",
        "print(dy_dbeta)\n",
        "print(dy_dgamma)\n",
        "#print(dy_dmu)\n",
        "print(dy_dkE)\n",
        "print(dy_dkS)\n",
        "print(dy_dkI)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfquTPnY-Eox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mu = 0.001\n",
        "S00 = Succeptible/PopulationBC\n",
        "E00 = 0.014\n",
        "I00 = Infected/PopulationBC\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGrJqZyy-TFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  alpha = alpha - mu*dy_dalpha\n",
        "  beta = beta - mu*dy_dbeta\n",
        "  gamma = gamma - mu*dy_dgamma\n",
        "  #mu = mu - mu*dy_dmu\n",
        "  kE = kE - mu*dy_dkE\n",
        "  kS = kS - mu*dy_dkS\n",
        "  kI = kI - mu*dy_dkI\n",
        "alpha.requires_grad = True\n",
        "beta.requires_grad = True\n",
        "gamma.requires_grad = True\n",
        "#mu.requires_grad = True\n",
        "kE.requires_grad = True\n",
        "kS.requires_grad = True\n",
        "kI.requires_grad = True\n",
        "\n",
        "beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF58DMUu_Izl",
        "colab_type": "code",
        "outputId": "82a3cd2e-6dac-4c08-a614-c9d1d36dfad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "dSdt, dEdt, dIdt = f(alpha,beta,gamma,mu,kE,kS,kI,S,E,I)\n",
        "\n",
        "dSdt.backward()\n",
        "dEdt.backward()\n",
        "dIdt.backward()\n",
        "\n",
        "dy_dalpha = alpha.grad\n",
        "dy_dbeta = beta.grad\n",
        "dy_dgamma = gamma.grad\n",
        "#dy_dmu = mu.grad\n",
        "dy_dkE = kE.grad\n",
        "dy_dKS = kS.grad\n",
        "dy_dkI = kI.grad\n",
        "\n",
        "print(dy_dalpha)\n",
        "print(dy_dbeta)\n",
        "print(dy_dgamma)\n",
        "#print(dy_dmu)\n",
        "print(dy_dkE)\n",
        "print(dy_dkS)\n",
        "print(dy_dkI)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-10ca2c4755c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdSdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdEdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdIdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdSdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdEdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdIdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjchXHuOtb40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(alpha,beta,gamma,mu,kE,kS,kI,S,E,I):  #Looks to be similar to SEImodel\n",
        "    \n",
        " \n",
        "      dSdt = -kS*L[1,1]*S - beta*E*S - gamma*I*S                 # dS/dt\n",
        "      #dEdt = kE*6*E + beta*E*S  + gamma*I*S - alpha*E      # dE/dt\n",
        "      #dIdt = -kI*6*I + alpha*E - mu*I                       # dI/dt\n",
        "     \n",
        "      return dSdt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujRfFGG6_Rpf",
        "colab_type": "code",
        "outputId": "7d900127-1d8d-4e08-e214-14412ff33303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    alpha = torch.rand(1, requires_grad=True)\n",
        "    beta  = torch.rand(1, requires_grad=True)\n",
        "    gamma = torch.rand(1, requires_grad=True)\n",
        "    mu    = torch.rand(1, requires_grad=True)\n",
        "    kE    = torch.rand(1, requires_grad=True)\n",
        "    kS    = torch.rand(1, requires_grad=True)\n",
        "    kI    = torch.rand(1, requires_grad=True)\n",
        "\n",
        "    num_iter = 100\n",
        "    my = 0.001\n",
        "\n",
        "    theta = torch.tensor([alpha, beta, gamma, mu, kE, kS, kI])\n",
        "\n",
        "\n",
        "    for i in range(num_iter):\n",
        "\n",
        "      dSdt = f(alpha, beta, gamma, mu, kE, kS, kI,S,E,I)\n",
        "      print(dSdt)\n",
        "    \n",
        "      dSdt.backward()\n",
        "  \n",
        "      if (i < 100) or (i%100 == 0):\n",
        "        print('Iter: %4d,   Loss: %6.4f, alpha: %6.4f, beta: %6.4f, gamma: %6.4f, kE: %6.4f, kS: %6.4f, kI: %6.4f' % (i, dSdt.item(), alpha.item(), beta.item(), gamma.item(), kE.item(), kS.item(), kI.item()))\n",
        "\n",
        "      with torch.no_grad():\n",
        "        #dy_dalpha = alpha.grad\n",
        "        dy_dbeta = beta.grad\n",
        "        dy_dgamma = gamma.grad\n",
        "        #dy_dmu = mu.grad\n",
        "        #dy_dkE = kE.grad\n",
        "        dy_dkS = kS.grad\n",
        "        #dy_dkI = kI.grad\n",
        "\n",
        "        #alpha.data = alpha - mu*dy_dalpha\n",
        "        beta.data   = beta - my*dy_dbeta\n",
        "        gamma.data  = gamma - my*dy_dgamma\n",
        "        #mu.data    = mu - mu*dy_dmu\n",
        "        #kE.data    = kE - mu*dy_dkE\n",
        "        kS.data     = kS - my*dy_dkS\n",
        "        #kI.data    = kI - mu*dy_dkI\n",
        "      \n",
        "        #alpha.grad.fill_(0.0)\n",
        "        beta.grad.fill_(0.0)\n",
        "        gamma.grad.fill_(0.0)\n",
        "        #mu.grad.fill_(0.0)\n",
        "        #kE.grad.fill_(0.0)\n",
        "        kS.grad.fill_(0.0)\n",
        "        #kI.grad.fill_(0.0)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.7926], grad_fn=<SubBackward0>)\n",
            "Iter:    0,   Loss: -0.7926, alpha: 0.1550, beta: 0.0861, gamma: 0.4734, kE: 0.2361, kS: 0.6366, kI: 0.3437\n",
            "tensor([-0.7940], grad_fn=<SubBackward0>)\n",
            "Iter:    1,   Loss: -0.7940, alpha: 0.1550, beta: 0.0861, gamma: 0.4735, kE: 0.2361, kS: 0.6378, kI: 0.3437\n",
            "tensor([-0.7955], grad_fn=<SubBackward0>)\n",
            "Iter:    2,   Loss: -0.7955, alpha: 0.1550, beta: 0.0861, gamma: 0.4736, kE: 0.2361, kS: 0.6390, kI: 0.3437\n",
            "tensor([-0.7969], grad_fn=<SubBackward0>)\n",
            "Iter:    3,   Loss: -0.7969, alpha: 0.1550, beta: 0.0861, gamma: 0.4736, kE: 0.2361, kS: 0.6402, kI: 0.3437\n",
            "tensor([-0.7983], grad_fn=<SubBackward0>)\n",
            "Iter:    4,   Loss: -0.7983, alpha: 0.1550, beta: 0.0861, gamma: 0.4737, kE: 0.2361, kS: 0.6414, kI: 0.3437\n",
            "tensor([-0.7998], grad_fn=<SubBackward0>)\n",
            "Iter:    5,   Loss: -0.7998, alpha: 0.1550, beta: 0.0861, gamma: 0.4737, kE: 0.2361, kS: 0.6426, kI: 0.3437\n",
            "tensor([-0.8012], grad_fn=<SubBackward0>)\n",
            "Iter:    6,   Loss: -0.8012, alpha: 0.1550, beta: 0.0861, gamma: 0.4738, kE: 0.2361, kS: 0.6438, kI: 0.3437\n",
            "tensor([-0.8027], grad_fn=<SubBackward0>)\n",
            "Iter:    7,   Loss: -0.8027, alpha: 0.1550, beta: 0.0861, gamma: 0.4739, kE: 0.2361, kS: 0.6450, kI: 0.3437\n",
            "tensor([-0.8041], grad_fn=<SubBackward0>)\n",
            "Iter:    8,   Loss: -0.8041, alpha: 0.1550, beta: 0.0861, gamma: 0.4739, kE: 0.2361, kS: 0.6462, kI: 0.3437\n",
            "tensor([-0.8056], grad_fn=<SubBackward0>)\n",
            "Iter:    9,   Loss: -0.8056, alpha: 0.1550, beta: 0.0861, gamma: 0.4740, kE: 0.2361, kS: 0.6474, kI: 0.3437\n",
            "tensor([-0.8070], grad_fn=<SubBackward0>)\n",
            "Iter:   10,   Loss: -0.8070, alpha: 0.1550, beta: 0.0861, gamma: 0.4740, kE: 0.2361, kS: 0.6486, kI: 0.3437\n",
            "tensor([-0.8085], grad_fn=<SubBackward0>)\n",
            "Iter:   11,   Loss: -0.8085, alpha: 0.1550, beta: 0.0862, gamma: 0.4741, kE: 0.2361, kS: 0.6498, kI: 0.3437\n",
            "tensor([-0.8099], grad_fn=<SubBackward0>)\n",
            "Iter:   12,   Loss: -0.8099, alpha: 0.1550, beta: 0.0862, gamma: 0.4742, kE: 0.2361, kS: 0.6510, kI: 0.3437\n",
            "tensor([-0.8113], grad_fn=<SubBackward0>)\n",
            "Iter:   13,   Loss: -0.8113, alpha: 0.1550, beta: 0.0862, gamma: 0.4742, kE: 0.2361, kS: 0.6522, kI: 0.3437\n",
            "tensor([-0.8128], grad_fn=<SubBackward0>)\n",
            "Iter:   14,   Loss: -0.8128, alpha: 0.1550, beta: 0.0862, gamma: 0.4743, kE: 0.2361, kS: 0.6534, kI: 0.3437\n",
            "tensor([-0.8142], grad_fn=<SubBackward0>)\n",
            "Iter:   15,   Loss: -0.8142, alpha: 0.1550, beta: 0.0862, gamma: 0.4743, kE: 0.2361, kS: 0.6546, kI: 0.3437\n",
            "tensor([-0.8157], grad_fn=<SubBackward0>)\n",
            "Iter:   16,   Loss: -0.8157, alpha: 0.1550, beta: 0.0862, gamma: 0.4744, kE: 0.2361, kS: 0.6558, kI: 0.3437\n",
            "tensor([-0.8171], grad_fn=<SubBackward0>)\n",
            "Iter:   17,   Loss: -0.8171, alpha: 0.1550, beta: 0.0862, gamma: 0.4745, kE: 0.2361, kS: 0.6570, kI: 0.3437\n",
            "tensor([-0.8186], grad_fn=<SubBackward0>)\n",
            "Iter:   18,   Loss: -0.8186, alpha: 0.1550, beta: 0.0862, gamma: 0.4745, kE: 0.2361, kS: 0.6582, kI: 0.3437\n",
            "tensor([-0.8200], grad_fn=<SubBackward0>)\n",
            "Iter:   19,   Loss: -0.8200, alpha: 0.1550, beta: 0.0862, gamma: 0.4746, kE: 0.2361, kS: 0.6594, kI: 0.3437\n",
            "tensor([-0.8214], grad_fn=<SubBackward0>)\n",
            "Iter:   20,   Loss: -0.8214, alpha: 0.1550, beta: 0.0862, gamma: 0.4746, kE: 0.2361, kS: 0.6606, kI: 0.3437\n",
            "tensor([-0.8229], grad_fn=<SubBackward0>)\n",
            "Iter:   21,   Loss: -0.8229, alpha: 0.1550, beta: 0.0862, gamma: 0.4747, kE: 0.2361, kS: 0.6618, kI: 0.3437\n",
            "tensor([-0.8243], grad_fn=<SubBackward0>)\n",
            "Iter:   22,   Loss: -0.8243, alpha: 0.1550, beta: 0.0862, gamma: 0.4748, kE: 0.2361, kS: 0.6630, kI: 0.3437\n",
            "tensor([-0.8258], grad_fn=<SubBackward0>)\n",
            "Iter:   23,   Loss: -0.8258, alpha: 0.1550, beta: 0.0862, gamma: 0.4748, kE: 0.2361, kS: 0.6642, kI: 0.3437\n",
            "tensor([-0.8272], grad_fn=<SubBackward0>)\n",
            "Iter:   24,   Loss: -0.8272, alpha: 0.1550, beta: 0.0862, gamma: 0.4749, kE: 0.2361, kS: 0.6654, kI: 0.3437\n",
            "tensor([-0.8287], grad_fn=<SubBackward0>)\n",
            "Iter:   25,   Loss: -0.8287, alpha: 0.1550, beta: 0.0862, gamma: 0.4749, kE: 0.2361, kS: 0.6666, kI: 0.3437\n",
            "tensor([-0.8301], grad_fn=<SubBackward0>)\n",
            "Iter:   26,   Loss: -0.8301, alpha: 0.1550, beta: 0.0862, gamma: 0.4750, kE: 0.2361, kS: 0.6678, kI: 0.3437\n",
            "tensor([-0.8315], grad_fn=<SubBackward0>)\n",
            "Iter:   27,   Loss: -0.8315, alpha: 0.1550, beta: 0.0862, gamma: 0.4751, kE: 0.2361, kS: 0.6690, kI: 0.3437\n",
            "tensor([-0.8330], grad_fn=<SubBackward0>)\n",
            "Iter:   28,   Loss: -0.8330, alpha: 0.1550, beta: 0.0862, gamma: 0.4751, kE: 0.2361, kS: 0.6702, kI: 0.3437\n",
            "tensor([-0.8344], grad_fn=<SubBackward0>)\n",
            "Iter:   29,   Loss: -0.8344, alpha: 0.1550, beta: 0.0862, gamma: 0.4752, kE: 0.2361, kS: 0.6714, kI: 0.3437\n",
            "tensor([-0.8359], grad_fn=<SubBackward0>)\n",
            "Iter:   30,   Loss: -0.8359, alpha: 0.1550, beta: 0.0862, gamma: 0.4752, kE: 0.2361, kS: 0.6726, kI: 0.3437\n",
            "tensor([-0.8373], grad_fn=<SubBackward0>)\n",
            "Iter:   31,   Loss: -0.8373, alpha: 0.1550, beta: 0.0862, gamma: 0.4753, kE: 0.2361, kS: 0.6738, kI: 0.3437\n",
            "tensor([-0.8388], grad_fn=<SubBackward0>)\n",
            "Iter:   32,   Loss: -0.8388, alpha: 0.1550, beta: 0.0862, gamma: 0.4754, kE: 0.2361, kS: 0.6750, kI: 0.3437\n",
            "tensor([-0.8402], grad_fn=<SubBackward0>)\n",
            "Iter:   33,   Loss: -0.8402, alpha: 0.1550, beta: 0.0862, gamma: 0.4754, kE: 0.2361, kS: 0.6762, kI: 0.3437\n",
            "tensor([-0.8417], grad_fn=<SubBackward0>)\n",
            "Iter:   34,   Loss: -0.8417, alpha: 0.1550, beta: 0.0862, gamma: 0.4755, kE: 0.2361, kS: 0.6774, kI: 0.3437\n",
            "tensor([-0.8431], grad_fn=<SubBackward0>)\n",
            "Iter:   35,   Loss: -0.8431, alpha: 0.1550, beta: 0.0862, gamma: 0.4755, kE: 0.2361, kS: 0.6786, kI: 0.3437\n",
            "tensor([-0.8445], grad_fn=<SubBackward0>)\n",
            "Iter:   36,   Loss: -0.8445, alpha: 0.1550, beta: 0.0862, gamma: 0.4756, kE: 0.2361, kS: 0.6798, kI: 0.3437\n",
            "tensor([-0.8460], grad_fn=<SubBackward0>)\n",
            "Iter:   37,   Loss: -0.8460, alpha: 0.1550, beta: 0.0862, gamma: 0.4757, kE: 0.2361, kS: 0.6810, kI: 0.3437\n",
            "tensor([-0.8474], grad_fn=<SubBackward0>)\n",
            "Iter:   38,   Loss: -0.8474, alpha: 0.1550, beta: 0.0862, gamma: 0.4757, kE: 0.2361, kS: 0.6822, kI: 0.3437\n",
            "tensor([-0.8489], grad_fn=<SubBackward0>)\n",
            "Iter:   39,   Loss: -0.8489, alpha: 0.1550, beta: 0.0862, gamma: 0.4758, kE: 0.2361, kS: 0.6834, kI: 0.3437\n",
            "tensor([-0.8503], grad_fn=<SubBackward0>)\n",
            "Iter:   40,   Loss: -0.8503, alpha: 0.1550, beta: 0.0862, gamma: 0.4758, kE: 0.2361, kS: 0.6846, kI: 0.3437\n",
            "tensor([-0.8518], grad_fn=<SubBackward0>)\n",
            "Iter:   41,   Loss: -0.8518, alpha: 0.1550, beta: 0.0862, gamma: 0.4759, kE: 0.2361, kS: 0.6858, kI: 0.3437\n",
            "tensor([-0.8532], grad_fn=<SubBackward0>)\n",
            "Iter:   42,   Loss: -0.8532, alpha: 0.1550, beta: 0.0862, gamma: 0.4760, kE: 0.2361, kS: 0.6870, kI: 0.3437\n",
            "tensor([-0.8546], grad_fn=<SubBackward0>)\n",
            "Iter:   43,   Loss: -0.8546, alpha: 0.1550, beta: 0.0862, gamma: 0.4760, kE: 0.2361, kS: 0.6882, kI: 0.3437\n",
            "tensor([-0.8561], grad_fn=<SubBackward0>)\n",
            "Iter:   44,   Loss: -0.8561, alpha: 0.1550, beta: 0.0863, gamma: 0.4761, kE: 0.2361, kS: 0.6894, kI: 0.3437\n",
            "tensor([-0.8575], grad_fn=<SubBackward0>)\n",
            "Iter:   45,   Loss: -0.8575, alpha: 0.1550, beta: 0.0863, gamma: 0.4761, kE: 0.2361, kS: 0.6906, kI: 0.3437\n",
            "tensor([-0.8590], grad_fn=<SubBackward0>)\n",
            "Iter:   46,   Loss: -0.8590, alpha: 0.1550, beta: 0.0863, gamma: 0.4762, kE: 0.2361, kS: 0.6918, kI: 0.3437\n",
            "tensor([-0.8604], grad_fn=<SubBackward0>)\n",
            "Iter:   47,   Loss: -0.8604, alpha: 0.1550, beta: 0.0863, gamma: 0.4763, kE: 0.2361, kS: 0.6930, kI: 0.3437\n",
            "tensor([-0.8619], grad_fn=<SubBackward0>)\n",
            "Iter:   48,   Loss: -0.8619, alpha: 0.1550, beta: 0.0863, gamma: 0.4763, kE: 0.2361, kS: 0.6942, kI: 0.3437\n",
            "tensor([-0.8633], grad_fn=<SubBackward0>)\n",
            "Iter:   49,   Loss: -0.8633, alpha: 0.1550, beta: 0.0863, gamma: 0.4764, kE: 0.2361, kS: 0.6954, kI: 0.3437\n",
            "tensor([-0.8648], grad_fn=<SubBackward0>)\n",
            "Iter:   50,   Loss: -0.8648, alpha: 0.1550, beta: 0.0863, gamma: 0.4764, kE: 0.2361, kS: 0.6966, kI: 0.3437\n",
            "tensor([-0.8662], grad_fn=<SubBackward0>)\n",
            "Iter:   51,   Loss: -0.8662, alpha: 0.1550, beta: 0.0863, gamma: 0.4765, kE: 0.2361, kS: 0.6978, kI: 0.3437\n",
            "tensor([-0.8676], grad_fn=<SubBackward0>)\n",
            "Iter:   52,   Loss: -0.8676, alpha: 0.1550, beta: 0.0863, gamma: 0.4766, kE: 0.2361, kS: 0.6990, kI: 0.3437\n",
            "tensor([-0.8691], grad_fn=<SubBackward0>)\n",
            "Iter:   53,   Loss: -0.8691, alpha: 0.1550, beta: 0.0863, gamma: 0.4766, kE: 0.2361, kS: 0.7002, kI: 0.3437\n",
            "tensor([-0.8705], grad_fn=<SubBackward0>)\n",
            "Iter:   54,   Loss: -0.8705, alpha: 0.1550, beta: 0.0863, gamma: 0.4767, kE: 0.2361, kS: 0.7014, kI: 0.3437\n",
            "tensor([-0.8720], grad_fn=<SubBackward0>)\n",
            "Iter:   55,   Loss: -0.8720, alpha: 0.1550, beta: 0.0863, gamma: 0.4767, kE: 0.2361, kS: 0.7026, kI: 0.3437\n",
            "tensor([-0.8734], grad_fn=<SubBackward0>)\n",
            "Iter:   56,   Loss: -0.8734, alpha: 0.1550, beta: 0.0863, gamma: 0.4768, kE: 0.2361, kS: 0.7038, kI: 0.3437\n",
            "tensor([-0.8749], grad_fn=<SubBackward0>)\n",
            "Iter:   57,   Loss: -0.8749, alpha: 0.1550, beta: 0.0863, gamma: 0.4769, kE: 0.2361, kS: 0.7050, kI: 0.3437\n",
            "tensor([-0.8763], grad_fn=<SubBackward0>)\n",
            "Iter:   58,   Loss: -0.8763, alpha: 0.1550, beta: 0.0863, gamma: 0.4769, kE: 0.2361, kS: 0.7062, kI: 0.3437\n",
            "tensor([-0.8777], grad_fn=<SubBackward0>)\n",
            "Iter:   59,   Loss: -0.8777, alpha: 0.1550, beta: 0.0863, gamma: 0.4770, kE: 0.2361, kS: 0.7074, kI: 0.3437\n",
            "tensor([-0.8792], grad_fn=<SubBackward0>)\n",
            "Iter:   60,   Loss: -0.8792, alpha: 0.1550, beta: 0.0863, gamma: 0.4770, kE: 0.2361, kS: 0.7086, kI: 0.3437\n",
            "tensor([-0.8806], grad_fn=<SubBackward0>)\n",
            "Iter:   61,   Loss: -0.8806, alpha: 0.1550, beta: 0.0863, gamma: 0.4771, kE: 0.2361, kS: 0.7098, kI: 0.3437\n",
            "tensor([-0.8821], grad_fn=<SubBackward0>)\n",
            "Iter:   62,   Loss: -0.8821, alpha: 0.1550, beta: 0.0863, gamma: 0.4772, kE: 0.2361, kS: 0.7110, kI: 0.3437\n",
            "tensor([-0.8835], grad_fn=<SubBackward0>)\n",
            "Iter:   63,   Loss: -0.8835, alpha: 0.1550, beta: 0.0863, gamma: 0.4772, kE: 0.2361, kS: 0.7122, kI: 0.3437\n",
            "tensor([-0.8850], grad_fn=<SubBackward0>)\n",
            "Iter:   64,   Loss: -0.8850, alpha: 0.1550, beta: 0.0863, gamma: 0.4773, kE: 0.2361, kS: 0.7134, kI: 0.3437\n",
            "tensor([-0.8864], grad_fn=<SubBackward0>)\n",
            "Iter:   65,   Loss: -0.8864, alpha: 0.1550, beta: 0.0863, gamma: 0.4773, kE: 0.2361, kS: 0.7146, kI: 0.3437\n",
            "tensor([-0.8879], grad_fn=<SubBackward0>)\n",
            "Iter:   66,   Loss: -0.8879, alpha: 0.1550, beta: 0.0863, gamma: 0.4774, kE: 0.2361, kS: 0.7158, kI: 0.3437\n",
            "tensor([-0.8893], grad_fn=<SubBackward0>)\n",
            "Iter:   67,   Loss: -0.8893, alpha: 0.1550, beta: 0.0863, gamma: 0.4775, kE: 0.2361, kS: 0.7170, kI: 0.3437\n",
            "tensor([-0.8907], grad_fn=<SubBackward0>)\n",
            "Iter:   68,   Loss: -0.8907, alpha: 0.1550, beta: 0.0863, gamma: 0.4775, kE: 0.2361, kS: 0.7182, kI: 0.3437\n",
            "tensor([-0.8922], grad_fn=<SubBackward0>)\n",
            "Iter:   69,   Loss: -0.8922, alpha: 0.1550, beta: 0.0863, gamma: 0.4776, kE: 0.2361, kS: 0.7194, kI: 0.3437\n",
            "tensor([-0.8936], grad_fn=<SubBackward0>)\n",
            "Iter:   70,   Loss: -0.8936, alpha: 0.1550, beta: 0.0863, gamma: 0.4776, kE: 0.2361, kS: 0.7206, kI: 0.3437\n",
            "tensor([-0.8951], grad_fn=<SubBackward0>)\n",
            "Iter:   71,   Loss: -0.8951, alpha: 0.1550, beta: 0.0863, gamma: 0.4777, kE: 0.2361, kS: 0.7218, kI: 0.3437\n",
            "tensor([-0.8965], grad_fn=<SubBackward0>)\n",
            "Iter:   72,   Loss: -0.8965, alpha: 0.1550, beta: 0.0863, gamma: 0.4778, kE: 0.2361, kS: 0.7230, kI: 0.3437\n",
            "tensor([-0.8980], grad_fn=<SubBackward0>)\n",
            "Iter:   73,   Loss: -0.8980, alpha: 0.1550, beta: 0.0863, gamma: 0.4778, kE: 0.2361, kS: 0.7242, kI: 0.3437\n",
            "tensor([-0.8994], grad_fn=<SubBackward0>)\n",
            "Iter:   74,   Loss: -0.8994, alpha: 0.1550, beta: 0.0863, gamma: 0.4779, kE: 0.2361, kS: 0.7254, kI: 0.3437\n",
            "tensor([-0.9008], grad_fn=<SubBackward0>)\n",
            "Iter:   75,   Loss: -0.9008, alpha: 0.1550, beta: 0.0863, gamma: 0.4779, kE: 0.2361, kS: 0.7266, kI: 0.3437\n",
            "tensor([-0.9023], grad_fn=<SubBackward0>)\n",
            "Iter:   76,   Loss: -0.9023, alpha: 0.1550, beta: 0.0863, gamma: 0.4780, kE: 0.2361, kS: 0.7278, kI: 0.3437\n",
            "tensor([-0.9037], grad_fn=<SubBackward0>)\n",
            "Iter:   77,   Loss: -0.9037, alpha: 0.1550, beta: 0.0863, gamma: 0.4781, kE: 0.2361, kS: 0.7290, kI: 0.3437\n",
            "tensor([-0.9052], grad_fn=<SubBackward0>)\n",
            "Iter:   78,   Loss: -0.9052, alpha: 0.1550, beta: 0.0864, gamma: 0.4781, kE: 0.2361, kS: 0.7302, kI: 0.3437\n",
            "tensor([-0.9066], grad_fn=<SubBackward0>)\n",
            "Iter:   79,   Loss: -0.9066, alpha: 0.1550, beta: 0.0864, gamma: 0.4782, kE: 0.2361, kS: 0.7314, kI: 0.3437\n",
            "tensor([-0.9081], grad_fn=<SubBackward0>)\n",
            "Iter:   80,   Loss: -0.9081, alpha: 0.1550, beta: 0.0864, gamma: 0.4782, kE: 0.2361, kS: 0.7326, kI: 0.3437\n",
            "tensor([-0.9095], grad_fn=<SubBackward0>)\n",
            "Iter:   81,   Loss: -0.9095, alpha: 0.1550, beta: 0.0864, gamma: 0.4783, kE: 0.2361, kS: 0.7338, kI: 0.3437\n",
            "tensor([-0.9109], grad_fn=<SubBackward0>)\n",
            "Iter:   82,   Loss: -0.9109, alpha: 0.1550, beta: 0.0864, gamma: 0.4784, kE: 0.2361, kS: 0.7350, kI: 0.3437\n",
            "tensor([-0.9124], grad_fn=<SubBackward0>)\n",
            "Iter:   83,   Loss: -0.9124, alpha: 0.1550, beta: 0.0864, gamma: 0.4784, kE: 0.2361, kS: 0.7362, kI: 0.3437\n",
            "tensor([-0.9138], grad_fn=<SubBackward0>)\n",
            "Iter:   84,   Loss: -0.9138, alpha: 0.1550, beta: 0.0864, gamma: 0.4785, kE: 0.2361, kS: 0.7374, kI: 0.3437\n",
            "tensor([-0.9153], grad_fn=<SubBackward0>)\n",
            "Iter:   85,   Loss: -0.9153, alpha: 0.1550, beta: 0.0864, gamma: 0.4785, kE: 0.2361, kS: 0.7386, kI: 0.3437\n",
            "tensor([-0.9167], grad_fn=<SubBackward0>)\n",
            "Iter:   86,   Loss: -0.9167, alpha: 0.1550, beta: 0.0864, gamma: 0.4786, kE: 0.2361, kS: 0.7398, kI: 0.3437\n",
            "tensor([-0.9182], grad_fn=<SubBackward0>)\n",
            "Iter:   87,   Loss: -0.9182, alpha: 0.1550, beta: 0.0864, gamma: 0.4787, kE: 0.2361, kS: 0.7410, kI: 0.3437\n",
            "tensor([-0.9196], grad_fn=<SubBackward0>)\n",
            "Iter:   88,   Loss: -0.9196, alpha: 0.1550, beta: 0.0864, gamma: 0.4787, kE: 0.2361, kS: 0.7422, kI: 0.3437\n",
            "tensor([-0.9211], grad_fn=<SubBackward0>)\n",
            "Iter:   89,   Loss: -0.9211, alpha: 0.1550, beta: 0.0864, gamma: 0.4788, kE: 0.2361, kS: 0.7434, kI: 0.3437\n",
            "tensor([-0.9225], grad_fn=<SubBackward0>)\n",
            "Iter:   90,   Loss: -0.9225, alpha: 0.1550, beta: 0.0864, gamma: 0.4788, kE: 0.2361, kS: 0.7446, kI: 0.3437\n",
            "tensor([-0.9239], grad_fn=<SubBackward0>)\n",
            "Iter:   91,   Loss: -0.9239, alpha: 0.1550, beta: 0.0864, gamma: 0.4789, kE: 0.2361, kS: 0.7458, kI: 0.3437\n",
            "tensor([-0.9254], grad_fn=<SubBackward0>)\n",
            "Iter:   92,   Loss: -0.9254, alpha: 0.1550, beta: 0.0864, gamma: 0.4790, kE: 0.2361, kS: 0.7470, kI: 0.3437\n",
            "tensor([-0.9268], grad_fn=<SubBackward0>)\n",
            "Iter:   93,   Loss: -0.9268, alpha: 0.1550, beta: 0.0864, gamma: 0.4790, kE: 0.2361, kS: 0.7482, kI: 0.3437\n",
            "tensor([-0.9283], grad_fn=<SubBackward0>)\n",
            "Iter:   94,   Loss: -0.9283, alpha: 0.1550, beta: 0.0864, gamma: 0.4791, kE: 0.2361, kS: 0.7494, kI: 0.3437\n",
            "tensor([-0.9297], grad_fn=<SubBackward0>)\n",
            "Iter:   95,   Loss: -0.9297, alpha: 0.1550, beta: 0.0864, gamma: 0.4791, kE: 0.2361, kS: 0.7506, kI: 0.3437\n",
            "tensor([-0.9312], grad_fn=<SubBackward0>)\n",
            "Iter:   96,   Loss: -0.9312, alpha: 0.1550, beta: 0.0864, gamma: 0.4792, kE: 0.2361, kS: 0.7518, kI: 0.3437\n",
            "tensor([-0.9326], grad_fn=<SubBackward0>)\n",
            "Iter:   97,   Loss: -0.9326, alpha: 0.1550, beta: 0.0864, gamma: 0.4793, kE: 0.2361, kS: 0.7530, kI: 0.3437\n",
            "tensor([-0.9340], grad_fn=<SubBackward0>)\n",
            "Iter:   98,   Loss: -0.9340, alpha: 0.1550, beta: 0.0864, gamma: 0.4793, kE: 0.2361, kS: 0.7542, kI: 0.3437\n",
            "tensor([-0.9355], grad_fn=<SubBackward0>)\n",
            "Iter:   99,   Loss: -0.9355, alpha: 0.1550, beta: 0.0864, gamma: 0.4794, kE: 0.2361, kS: 0.7554, kI: 0.3437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAYynelD7JZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g(alpha,beta,gamma,mu,kE,kS,kI,S,E,I):  #Looks to be similar to SEImodel\n",
        "    \n",
        "    F = torch.zeros(3)\n",
        "    F[0]  = -kS*L[n,n]*S - beta*E*S - gamma*I*S                 # dS/dt\n",
        "    F[1]  = -kE*L[n,n]*E + beta*E*S  + gamma*I*S - alpha*E      # dE/dt\n",
        "    F[2]  = -kI*L[n,n]*I + alpha*E - mu*I                       # dI/dt\n",
        "    \n",
        "    return F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ2jr307zizv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67e154c7-4596-46ca-fda7-f67e7f9fead3"
      },
      "source": [
        "    alpha = torch.rand(1, requires_grad=True)\n",
        "    beta  = torch.rand(1, requires_grad=True)\n",
        "    gamma = torch.rand(1, requires_grad=True)\n",
        "    mu    = torch.rand(1, requires_grad=True)\n",
        "    kE    = torch.rand(1, requires_grad=True)\n",
        "    kS    = torch.rand(1, requires_grad=True)\n",
        "    kI    = torch.rand(1, requires_grad=True)\n",
        "\n",
        "    num_iter = 100\n",
        "    my = 0.001\n",
        "\n",
        "    theta = torch.tensor([alpha, beta, gamma, mu, kE, kS, kI])\n",
        "\n",
        "    S = 0.2\n",
        "    E = 0.015\n",
        "    I = 0.3\n",
        "\n",
        "    for i in range(num_iter):\n",
        "\n",
        "      y = g(alpha, beta, gamma, mu, kE, kS, kI,S,E,I)\n",
        "      print(y)\n",
        "    \n",
        "      for u in range(3):\n",
        "        y[u].backward(retain_graph=True)\n",
        "   \n",
        "        if (i < 100) or (i%100 == 0):\n",
        "          print('Iter: %4d,   Loss: %6.4f, alpha: %6.4f, beta: %6.4f, gamma: %6.4f, kE: %6.4f, kS: %6.4f, kI: %6.4f' % (i, y[u].item(), alpha.item(), beta.item(), gamma.item(), kE.item(), kS.item(), kI.item()))\n",
        "\n",
        "        with torch.no_grad():\n",
        "          dy_dalpha = alpha.grad\n",
        "          dy_dbeta = beta.grad\n",
        "          dy_dgamma = gamma.grad\n",
        "          dy_dmu = mu.grad\n",
        "          dy_dkE = kE.grad\n",
        "          dy_dkS = kS.grad\n",
        "          dy_dkI = kI.grad\n",
        "\n",
        "          alpha.data = alpha - mu*dy_dalpha\n",
        "          beta.data   = beta - my*dy_dbeta\n",
        "          gamma.data  = gamma - my*dy_dgamma\n",
        "          mu.data    = mu - mu*dy_dmu\n",
        "          kE.data    = kE - mu*dy_dkE\n",
        "          kS.data     = kS - my*dy_dkS\n",
        "          kI.data    = kI - mu*dy_dkI\n",
        "      \n",
        "          alpha.grad.fill_(0.0)\n",
        "          beta.grad.fill_(0.0)\n",
        "          gamma.grad.fill_(0.0)\n",
        "          mu.grad.fill_(0.0)\n",
        "          kE.grad.fill_(0.0)\n",
        "          kS.grad.fill_(0.0)\n",
        "          kI.grad.fill_(0.0)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.8870,  0.0052, -1.5405], grad_fn=<CopySlices>)\n",
            "Iter:    0,   Loss: -0.8870, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 0.0301, kS: 0.7230, kI: 0.7600\n",
            "Iter:    0,   Loss: 0.0052, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 0.0301, kS: 0.7242, kI: 0.7600\n",
            "Iter:    0,   Loss: -1.5405, alpha: 0.7756, beta: 0.2650, gamma: 0.3098, kE: 0.0854, kS: 0.7242, kI: 0.7600\n",
            "tensor([-8.8841e-01,  2.0514e-04, -4.1800e+00], grad_fn=<CopySlices>)\n",
            "Iter:    1,   Loss: -0.8884, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 0.0854, kS: 0.7242, kI: 2.1957\n",
            "Iter:    1,   Loss: 0.0002, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 0.0854, kS: 0.7254, kI: 2.1957\n",
            "Iter:    1,   Loss: -4.1800, alpha: 0.7783, beta: 0.2650, gamma: 0.3098, kE: 0.1571, kS: 0.7254, kI: 2.1957\n",
            "tensor([-8.8985e-01, -6.2555e-03, -7.6113e+00], grad_fn=<CopySlices>)\n",
            "Iter:    2,   Loss: -0.8899, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 0.1571, kS: 0.7254, kI: 4.0621\n",
            "Iter:    2,   Loss: -0.0063, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 0.1571, kS: 0.7266, kI: 4.0621\n",
            "Iter:    2,   Loss: -7.6113, alpha: 0.7819, beta: 0.2650, gamma: 0.3098, kE: 0.2505, kS: 0.7266, kI: 4.0621\n",
            "tensor([ -0.8913,  -0.0147, -12.0720], grad_fn=<CopySlices>)\n",
            "Iter:    3,   Loss: -0.8913, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 0.2505, kS: 0.7266, kI: 6.4884\n",
            "Iter:    3,   Loss: -0.0147, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 0.2505, kS: 0.7278, kI: 6.4884\n",
            "Iter:    3,   Loss: -12.0720, alpha: 0.7866, beta: 0.2650, gamma: 0.3098, kE: 0.3718, kS: 0.7278, kI: 6.4884\n",
            "tensor([ -0.8927,  -0.0256, -17.8710], grad_fn=<CopySlices>)\n",
            "Iter:    4,   Loss: -0.8927, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 0.3718, kS: 0.7278, kI: 9.6427\n",
            "Iter:    4,   Loss: -0.0256, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 0.3718, kS: 0.7290, kI: 9.6427\n",
            "Iter:    4,   Loss: -17.8710, alpha: 0.7927, beta: 0.2650, gamma: 0.3098, kE: 0.5295, kS: 0.7290, kI: 9.6427\n",
            "tensor([ -0.8942,  -0.0398, -25.4096], grad_fn=<CopySlices>)\n",
            "Iter:    5,   Loss: -0.8942, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 0.5295, kS: 0.7290, kI: 13.7432\n",
            "Iter:    5,   Loss: -0.0398, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 0.5295, kS: 0.7302, kI: 13.7432\n",
            "Iter:    5,   Loss: -25.4096, alpha: 0.8006, beta: 0.2650, gamma: 0.3098, kE: 0.7345, kS: 0.7302, kI: 13.7432\n",
            "tensor([ -0.8956,  -0.0582, -35.2098], grad_fn=<CopySlices>)\n",
            "Iter:    6,   Loss: -0.8956, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 0.7345, kS: 0.7302, kI: 19.0738\n",
            "Iter:    6,   Loss: -0.0582, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 0.7345, kS: 0.7314, kI: 19.0738\n",
            "Iter:    6,   Loss: -35.2098, alpha: 0.8108, beta: 0.2650, gamma: 0.3098, kE: 1.0010, kS: 0.7314, kI: 19.0738\n",
            "tensor([ -0.8971,  -0.0822, -47.9501], grad_fn=<CopySlices>)\n",
            "Iter:    7,   Loss: -0.8971, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 1.0010, kS: 0.7314, kI: 26.0037\n",
            "Iter:    7,   Loss: -0.0822, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 1.0010, kS: 0.7326, kI: 26.0037\n",
            "Iter:    7,   Loss: -47.9501, alpha: 0.8241, beta: 0.2650, gamma: 0.3098, kE: 1.3475, kS: 0.7326, kI: 26.0037\n",
            "tensor([ -0.8985,  -0.1134, -64.5124], grad_fn=<CopySlices>)\n",
            "Iter:    8,   Loss: -0.8985, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 1.3475, kS: 0.7326, kI: 35.0125\n",
            "Iter:    8,   Loss: -0.1134, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 1.3475, kS: 0.7338, kI: 35.0125\n",
            "Iter:    8,   Loss: -64.5124, alpha: 0.8415, beta: 0.2650, gamma: 0.3098, kE: 1.7980, kS: 0.7338, kI: 35.0125\n",
            "tensor([ -0.8999,  -0.1539, -86.0435], grad_fn=<CopySlices>)\n",
            "Iter:    9,   Loss: -0.8999, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 1.7980, kS: 0.7338, kI: 46.7239\n",
            "Iter:    9,   Loss: -0.1539, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 1.7980, kS: 0.7350, kI: 46.7239\n",
            "Iter:    9,   Loss: -86.0435, alpha: 0.8640, beta: 0.2650, gamma: 0.3098, kE: 2.3836, kS: 0.7350, kI: 46.7239\n",
            "tensor([  -0.9014,   -0.2066, -114.0339], grad_fn=<CopySlices>)\n",
            "Iter:   10,   Loss: -0.9014, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 2.3836, kS: 0.7350, kI: 61.9488\n",
            "Iter:   10,   Loss: -0.2066, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 2.3836, kS: 0.7362, kI: 61.9488\n",
            "Iter:   10,   Loss: -114.0339, alpha: 0.8933, beta: 0.2650, gamma: 0.3098, kE: 3.1448, kS: 0.7362, kI: 61.9488\n",
            "tensor([  -0.9028,   -0.2751, -150.4214], grad_fn=<CopySlices>)\n",
            "Iter:   11,   Loss: -0.9028, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 3.1448, kS: 0.7362, kI: 81.7412\n",
            "Iter:   11,   Loss: -0.2751, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 3.1448, kS: 0.7374, kI: 81.7412\n",
            "Iter:   11,   Loss: -150.4214, alpha: 0.9313, beta: 0.2650, gamma: 0.3098, kE: 4.1344, kS: 0.7374, kI: 81.7412\n",
            "tensor([  -0.9043,   -0.3642, -197.7251], grad_fn=<CopySlices>)\n",
            "Iter:   12,   Loss: -0.9043, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 4.1344, kS: 0.7374, kI: 107.4712\n",
            "Iter:   12,   Loss: -0.3642, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 4.1344, kS: 0.7386, kI: 107.4712\n",
            "Iter:   12,   Loss: -197.7251, alpha: 0.9808, beta: 0.2650, gamma: 0.3098, kE: 5.4209, kS: 0.7386, kI: 107.4712\n",
            "tensor([  -0.9057,   -0.4800, -259.2199], grad_fn=<CopySlices>)\n",
            "Iter:   13,   Loss: -0.9057, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 5.4209, kS: 0.7386, kI: 140.9203\n",
            "Iter:   13,   Loss: -0.4800, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 5.4209, kS: 0.7398, kI: 140.9203\n",
            "Iter:   13,   Loss: -259.2199, alpha: 1.0451, beta: 0.2650, gamma: 0.3098, kE: 7.0934, kS: 0.7398, kI: 140.9203\n",
            "tensor([  -0.9071,   -0.6305, -339.1633], grad_fn=<CopySlices>)\n",
            "Iter:   14,   Loss: -0.9071, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 7.0934, kS: 0.7398, kI: 184.4041\n",
            "Iter:   14,   Loss: -0.6305, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 7.0934, kS: 0.7410, kI: 184.4041\n",
            "Iter:   14,   Loss: -339.1633, alpha: 1.1287, beta: 0.2650, gamma: 0.3098, kE: 9.2676, kS: 0.7410, kI: 184.4041\n",
            "tensor([  -0.9086,   -0.8262, -443.0895], grad_fn=<CopySlices>)\n",
            "Iter:   15,   Loss: -0.9086, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 9.2676, kS: 0.7410, kI: 240.9331\n",
            "Iter:   15,   Loss: -0.8262, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 9.2676, kS: 0.7422, kI: 240.9331\n",
            "Iter:   15,   Loss: -443.0895, alpha: 1.2375, beta: 0.2650, gamma: 0.3098, kE: 12.0940, kS: 0.7422, kI: 240.9331\n",
            "tensor([  -0.9100,   -1.0806, -578.1938], grad_fn=<CopySlices>)\n",
            "Iter:   16,   Loss: -0.9100, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 12.0940, kS: 0.7422, kI: 314.4207\n",
            "Iter:   16,   Loss: -1.0806, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 12.0940, kS: 0.7434, kI: 314.4207\n",
            "Iter:   16,   Loss: -578.1938, alpha: 1.3788, beta: 0.2650, gamma: 0.3098, kE: 15.7684, kS: 0.7434, kI: 314.4207\n",
            "tensor([  -0.9115,   -1.4113, -753.8293], grad_fn=<CopySlices>)\n",
            "Iter:   17,   Loss: -0.9115, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 15.7684, kS: 0.7434, kI: 409.9547\n",
            "Iter:   17,   Loss: -1.4113, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 15.7684, kS: 0.7446, kI: 409.9547\n",
            "Iter:   17,   Loss: -753.8293, alpha: 1.5625, beta: 0.2650, gamma: 0.3098, kE: 20.5451, kS: 0.7446, kI: 409.9547\n",
            "tensor([-9.1289e-01, -1.8412e+00, -9.8216e+02], grad_fn=<CopySlices>)\n",
            "Iter:   18,   Loss: -0.9129, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 20.5451, kS: 0.7446, kI: 534.1487\n",
            "Iter:   18,   Loss: -1.8412, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 20.5451, kS: 0.7458, kI: 534.1487\n",
            "Iter:   18,   Loss: -982.1554, alpha: 1.8013, beta: 0.2650, gamma: 0.3098, kE: 26.7548, kS: 0.7458, kI: 534.1487\n",
            "tensor([-9.1433e-01, -2.4000e+00, -1.2790e+03], grad_fn=<CopySlices>)\n",
            "Iter:   19,   Loss: -0.9143, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 26.7548, kS: 0.7458, kI: 695.6011\n",
            "Iter:   19,   Loss: -2.4000, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 26.7548, kS: 0.7470, kI: 695.6011\n",
            "Iter:   19,   Loss: -1278.9792, alpha: 2.1118, beta: 0.2650, gamma: 0.3098, kE: 34.8274, kS: 0.7470, kI: 695.6011\n",
            "tensor([-9.1577e-01, -3.1266e+00, -1.6649e+03], grad_fn=<CopySlices>)\n",
            "Iter:   20,   Loss: -0.9158, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 34.8274, kS: 0.7470, kI: 905.4891\n",
            "Iter:   20,   Loss: -3.1266, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 34.8274, kS: 0.7482, kI: 905.4891\n",
            "Iter:   20,   Loss: -1664.8503, alpha: 2.5155, beta: 0.2650, gamma: 0.3098, kE: 45.3218, kS: 0.7482, kI: 905.4891\n",
            "tensor([-9.1721e-01, -4.0711e+00, -2.1665e+03], grad_fn=<CopySlices>)\n",
            "Iter:   21,   Loss: -0.9172, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 45.3218, kS: 0.7482, kI: 1178.3436\n",
            "Iter:   21,   Loss: -4.0711, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 45.3218, kS: 0.7494, kI: 1178.3436\n",
            "Iter:   21,   Loss: -2166.4829, alpha: 3.0402, beta: 0.2650, gamma: 0.3098, kE: 58.9645, kS: 0.7494, kI: 1178.3436\n",
            "tensor([-9.1865e-01, -5.2989e+00, -2.8186e+03], grad_fn=<CopySlices>)\n",
            "Iter:   22,   Loss: -0.9187, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 58.9645, kS: 0.7494, kI: 1533.0544\n",
            "Iter:   22,   Loss: -5.2989, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 58.9645, kS: 0.7506, kI: 1533.0544\n",
            "Iter:   22,   Loss: -2818.6050, alpha: 3.7223, beta: 0.2650, gamma: 0.3098, kE: 76.7001, kS: 0.7506, kI: 1533.0544\n",
            "tensor([-9.2009e-01, -6.8951e+00, -3.6664e+03], grad_fn=<CopySlices>)\n",
            "Iter:   23,   Loss: -0.9201, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 76.7001, kS: 0.7506, kI: 1994.1785\n",
            "Iter:   23,   Loss: -6.8951, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 76.7001, kS: 0.7518, kI: 1994.1785\n",
            "Iter:   23,   Loss: -3666.3638, alpha: 4.6091, beta: 0.2650, gamma: 0.3098, kE: 99.7563, kS: 0.7518, kI: 1994.1785\n",
            "tensor([-9.2153e-01, -8.9702e+00, -4.7685e+03], grad_fn=<CopySlices>)\n",
            "Iter:   24,   Loss: -0.9215, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 99.7563, kS: 0.7518, kI: 2593.6396\n",
            "Iter:   24,   Loss: -8.9702, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 99.7563, kS: 0.7530, kI: 2593.6396\n",
            "Iter:   24,   Loss: -4768.4502, alpha: 5.7619, beta: 0.2650, gamma: 0.3098, kE: 129.7293, kS: 0.7530, kI: 2593.6396\n",
            "tensor([-9.2297e-01, -1.1668e+01, -6.2012e+03], grad_fn=<CopySlices>)\n",
            "Iter:   25,   Loss: -0.9230, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 129.7293, kS: 0.7530, kI: 3372.9392\n",
            "Iter:   25,   Loss: -11.6678, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 129.7293, kS: 0.7542, kI: 3372.9392\n",
            "Iter:   25,   Loss: -6201.1621, alpha: 7.2605, beta: 0.2650, gamma: 0.3098, kE: 168.6943, kS: 0.7542, kI: 3372.9392\n",
            "tensor([-9.2441e-01, -1.5175e+01, -8.0637e+03], grad_fn=<CopySlices>)\n",
            "Iter:   26,   Loss: -0.9244, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 168.6943, kS: 0.7542, kI: 4386.0288\n",
            "Iter:   26,   Loss: -15.1746, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 168.6943, kS: 0.7554, kI: 4386.0288\n",
            "Iter:   26,   Loss: -8063.6885, alpha: 9.2088, beta: 0.2650, gamma: 0.3098, kE: 219.3488, kS: 0.7554, kI: 4386.0288\n",
            "tensor([-9.2585e-01, -1.9734e+01, -1.0485e+04], grad_fn=<CopySlices>)\n",
            "Iter:   27,   Loss: -0.9259, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 219.3488, kS: 0.7554, kI: 5703.0454\n",
            "Iter:   27,   Loss: -19.7335, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 219.3488, kS: 0.7566, kI: 5703.0454\n",
            "Iter:   27,   Loss: -10484.9736, alpha: 11.7415, beta: 0.2650, gamma: 0.3098, kE: 285.1996, kS: 0.7566, kI: 5703.0454\n",
            "tensor([-9.2729e-01, -2.5660e+01, -1.3633e+04], grad_fn=<CopySlices>)\n",
            "Iter:   28,   Loss: -0.9273, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 285.1996, kS: 0.7566, kI: 7415.1670\n",
            "Iter:   28,   Loss: -25.6601, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 285.1996, kS: 0.7578, kI: 7415.1670\n",
            "Iter:   28,   Loss: -13632.6426, alpha: 15.0341, beta: 0.2650, gamma: 0.3098, kE: 370.8057, kS: 0.7578, kI: 7415.1670\n",
            "tensor([-9.2873e-01, -3.3365e+01, -1.7725e+04], grad_fn=<CopySlices>)\n",
            "Iter:   29,   Loss: -0.9287, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 370.8057, kS: 0.7578, kI: 9640.9248\n",
            "Iter:   29,   Loss: -33.3646, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 370.8057, kS: 0.7590, kI: 9640.9248\n",
            "Iter:   29,   Loss: -17724.6113, alpha: 19.3144, beta: 0.2650, gamma: 0.3098, kE: 482.0936, kS: 0.7590, kI: 9640.9248\n",
            "tensor([-9.3017e-01, -4.3381e+01, -2.3044e+04], grad_fn=<CopySlices>)\n",
            "Iter:   30,   Loss: -0.9302, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 482.0936, kS: 0.7590, kI: 12534.4102\n",
            "Iter:   30,   Loss: -43.3805, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 482.0936, kS: 0.7602, kI: 12534.4102\n",
            "Iter:   30,   Loss: -23044.1758, alpha: 24.8788, beta: 0.2650, gamma: 0.3098, kE: 626.7678, kS: 0.7602, kI: 12534.4102\n",
            "tensor([-9.3161e-01, -5.6401e+01, -2.9960e+04], grad_fn=<CopySlices>)\n",
            "Iter:   31,   Loss: -0.9316, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 626.7678, kS: 0.7602, kI: 16295.9414\n",
            "Iter:   31,   Loss: -56.4012, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 626.7678, kS: 0.7614, kI: 16295.9414\n",
            "Iter:   31,   Loss: -29959.6055, alpha: 32.1125, beta: 0.2650, gamma: 0.3098, kE: 814.8444, kS: 0.7614, kI: 16295.9414\n",
            "tensor([-9.3305e-01, -7.3328e+01, -3.8950e+04], grad_fn=<CopySlices>)\n",
            "Iter:   32,   Loss: -0.9331, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 814.8444, kS: 0.7614, kI: 21185.9316\n",
            "Iter:   32,   Loss: -73.3281, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 814.8444, kS: 0.7626, kI: 21185.9316\n",
            "Iter:   32,   Loss: -38949.6680, alpha: 41.5163, beta: 0.2650, gamma: 0.3098, kE: 1059.3439, kS: 0.7626, kI: 21185.9316\n",
            "tensor([-9.3449e-01, -9.5333e+01, -5.0637e+04], grad_fn=<CopySlices>)\n",
            "Iter:   33,   Loss: -0.9345, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 1059.3439, kS: 0.7626, kI: 27542.9180\n",
            "Iter:   33,   Loss: -95.3331, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 1059.3439, kS: 0.7638, kI: 27542.9180\n",
            "Iter:   33,   Loss: -50636.7383, alpha: 53.7413, beta: 0.2650, gamma: 0.3098, kE: 1377.1932, kS: 0.7638, kI: 27542.9180\n",
            "tensor([-9.3593e-01, -1.2394e+02, -6.5830e+04], grad_fn=<CopySlices>)\n",
            "Iter:   34,   Loss: -0.9359, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 1377.1932, kS: 0.7638, kI: 35807.0000\n",
            "Iter:   34,   Loss: -123.9395, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 1377.1932, kS: 0.7650, kI: 35807.0000\n",
            "Iter:   34,   Loss: -65829.9375, alpha: 69.6337, beta: 0.2650, gamma: 0.3098, kE: 1790.3973, kS: 0.7650, kI: 35807.0000\n",
            "tensor([-9.3737e-01, -1.6113e+02, -8.5581e+04], grad_fn=<CopySlices>)\n",
            "Iter:   35,   Loss: -0.9374, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 1790.3973, kS: 0.7650, kI: 46550.3086\n",
            "Iter:   35,   Loss: -161.1279, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 1790.3973, kS: 0.7662, kI: 46550.3086\n",
            "Iter:   35,   Loss: -85581.1016, alpha: 90.2940, beta: 0.2650, gamma: 0.3098, kE: 2327.5627, kS: 0.7662, kI: 46550.3086\n",
            "tensor([-9.3881e-01, -2.0947e+02, -1.1126e+05], grad_fn=<CopySlices>)\n",
            "Iter:   36,   Loss: -0.9388, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 2327.5627, kS: 0.7662, kI: 60516.6094\n",
            "Iter:   36,   Loss: -209.4728, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 2327.5627, kS: 0.7674, kI: 60516.6094\n",
            "Iter:   36,   Loss: -111257.6094, alpha: 117.1522, beta: 0.2650, gamma: 0.3098, kE: 3025.8777, kS: 0.7674, kI: 60516.6094\n",
            "tensor([-9.4025e-01, -2.7232e+02, -1.4464e+05], grad_fn=<CopySlices>)\n",
            "Iter:   37,   Loss: -0.9403, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 3025.8777, kS: 0.7674, kI: 78672.7969\n",
            "Iter:   37,   Loss: -272.3211, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 3025.8777, kS: 0.7686, kI: 78672.7969\n",
            "Iter:   37,   Loss: -144637.0625, alpha: 152.0680, beta: 0.2650, gamma: 0.3098, kE: 3933.6873, kS: 0.7686, kI: 78672.7969\n",
            "tensor([-9.4169e-01, -3.5402e+02, -1.8803e+05], grad_fn=<CopySlices>)\n",
            "Iter:   38,   Loss: -0.9417, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 3933.6873, kS: 0.7686, kI: 102275.8438\n",
            "Iter:   38,   Loss: -354.0240, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 3933.6873, kS: 0.7698, kI: 102275.8438\n",
            "Iter:   38,   Loss: -188030.3594, alpha: 197.4585, beta: 0.2650, gamma: 0.3098, kE: 5113.8398, kS: 0.7698, kI: 102275.8438\n",
            "tensor([-9.4313e-01, -4.6024e+02, -2.4444e+05], grad_fn=<CopySlices>)\n",
            "Iter:   39,   Loss: -0.9431, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 5113.8398, kS: 0.7698, kI: 132959.8125\n",
            "Iter:   39,   Loss: -460.2377, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 5113.8398, kS: 0.7710, kI: 132959.8125\n",
            "Iter:   39,   Loss: -244441.6562, alpha: 256.4661, beta: 0.2650, gamma: 0.3098, kE: 6648.0381, kS: 0.7710, kI: 132959.8125\n",
            "tensor([-9.4457e-01, -5.9832e+02, -3.1778e+05], grad_fn=<CopySlices>)\n",
            "Iter:   40,   Loss: -0.9446, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 6648.0381, kS: 0.7710, kI: 172848.9688\n",
            "Iter:   40,   Loss: -598.3154, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 6648.0381, kS: 0.7722, kI: 172848.9688\n",
            "Iter:   40,   Loss: -317776.3438, alpha: 333.1760, beta: 0.2650, gamma: 0.3098, kE: 8642.4961, kS: 0.7722, kI: 172848.9688\n",
            "tensor([-9.4601e-01, -7.7782e+02, -4.1311e+05], grad_fn=<CopySlices>)\n",
            "Iter:   41,   Loss: -0.9460, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 8642.4961, kS: 0.7722, kI: 224704.8750\n",
            "Iter:   41,   Loss: -777.8167, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 8642.4961, kS: 0.7734, kI: 224704.8750\n",
            "Iter:   41,   Loss: -413111.4375, alpha: 432.8988, beta: 0.2650, gamma: 0.3098, kE: 11235.2910, kS: 0.7734, kI: 224704.8750\n",
            "tensor([-9.4745e-01, -1.0112e+03, -5.3705e+05], grad_fn=<CopySlices>)\n",
            "Iter:   42,   Loss: -0.9475, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 11235.2910, kS: 0.7734, kI: 292117.5625\n",
            "Iter:   42,   Loss: -1011.1683, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 11235.2910, kS: 0.7746, kI: 292117.5625\n",
            "Iter:   42,   Loss: -537047.0625, alpha: 562.5386, beta: 0.2650, gamma: 0.3098, kE: 14605.9248, kS: 0.7746, kI: 292117.5625\n",
            "tensor([-9.4889e-01, -1.3145e+03, -6.9816e+05], grad_fn=<CopySlices>)\n",
            "Iter:   43,   Loss: -0.9489, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 14605.9248, kS: 0.7746, kI: 379754.0312\n",
            "Iter:   43,   Loss: -1314.5253, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 14605.9248, kS: 0.7758, kI: 379754.0312\n",
            "Iter:   43,   Loss: -698163.3750, alpha: 731.0703, beta: 0.2650, gamma: 0.3098, kE: 18987.7480, kS: 0.7758, kI: 379754.0312\n",
            "tensor([-9.5033e-01, -1.7089e+03, -9.0761e+05], grad_fn=<CopySlices>)\n",
            "Iter:   44,   Loss: -0.9503, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 18987.7480, kS: 0.7758, kI: 493681.4375\n",
            "Iter:   44,   Loss: -1708.8893, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 18987.7480, kS: 0.7770, kI: 493681.4375\n",
            "Iter:   44,   Loss: -907614.4375, alpha: 950.1614, beta: 0.2650, gamma: 0.3098, kE: 24684.1191, kS: 0.7770, kI: 493681.4375\n",
            "tensor([-9.5177e-01, -2.2216e+03, -1.1799e+06], grad_fn=<CopySlices>)\n",
            "Iter:   45,   Loss: -0.9518, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 24684.1191, kS: 0.7770, kI: 641787.0625\n",
            "Iter:   45,   Loss: -2221.5630, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 24684.1191, kS: 0.7782, kI: 641787.0625\n",
            "Iter:   45,   Loss: -1179901.0000, alpha: 1234.9800, beta: 0.2650, gamma: 0.3098, kE: 32089.4004, kS: 0.7782, kI: 641787.0625\n",
            "tensor([-9.5321e-01, -2.8880e+03, -1.5339e+06], grad_fn=<CopySlices>)\n",
            "Iter:   46,   Loss: -0.9532, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 32089.4004, kS: 0.7782, kI: 834324.3750\n",
            "Iter:   46,   Loss: -2888.0383, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 32089.4004, kS: 0.7794, kI: 834324.3750\n",
            "Iter:   46,   Loss: -1533873.3750, alpha: 1605.2440, beta: 0.2650, gamma: 0.3098, kE: 41716.2656, kS: 0.7794, kI: 834324.3750\n",
            "tensor([-9.5465e-01, -3.7545e+03, -1.9940e+06], grad_fn=<CopySlices>)\n",
            "Iter:   47,   Loss: -0.9547, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 41716.2656, kS: 0.7794, kI: 1084622.8750\n",
            "Iter:   47,   Loss: -3754.4561, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 41716.2656, kS: 0.7806, kI: 1084622.8750\n",
            "Iter:   47,   Loss: -1994037.5000, alpha: 2086.5874, beta: 0.2650, gamma: 0.3098, kE: 54231.1914, kS: 0.7806, kI: 1084622.8750\n",
            "tensor([-9.5609e-01, -4.8808e+03, -2.5923e+06], grad_fn=<CopySlices>)\n",
            "Iter:   48,   Loss: -0.9561, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 54231.1914, kS: 0.7806, kI: 1410011.0000\n",
            "Iter:   48,   Loss: -4880.7993, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 54231.1914, kS: 0.7818, kI: 1410011.0000\n",
            "Iter:   48,   Loss: -2592251.2500, alpha: 2712.3337, beta: 0.2650, gamma: 0.3098, kE: 70500.5938, kS: 0.7818, kI: 1410011.0000\n",
            "tensor([-9.5753e-01, -6.3450e+03, -3.3699e+06], grad_fn=<CopySlices>)\n",
            "Iter:   49,   Loss: -0.9575, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 70500.5938, kS: 0.7818, kI: 1833015.5000\n",
            "Iter:   49,   Loss: -6345.0454, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 70500.5938, kS: 0.7830, kI: 1833015.5000\n",
            "Iter:   49,   Loss: -3369928.7500, alpha: 3525.8037, beta: 0.2650, gamma: 0.3098, kE: 91650.8203, kS: 0.7830, kI: 1833015.5000\n",
            "tensor([-9.5897e-01, -8.2486e+03, -4.3809e+06], grad_fn=<CopySlices>)\n",
            "Iter:   50,   Loss: -0.9590, alpha: 0.7664, beta: 0.2650, gamma: 0.3098, kE: 91650.8203, kS: 0.7830, kI: 2382921.5000\n",
            "Iter:   50,   Loss: -8248.5664, alpha: 0.7664, beta: 0.2650, gamma: 0.3099, kE: 91650.8203, kS: 0.7842, kI: 2382921.5000\n",
            "Iter:   50,   Loss: -4380910.0000, alpha: 4583.3154, beta: 0.2650, gamma: 0.3098, kE: 119146.1094, kS: 0.7842, kI: 2382921.5000\n",
            "tensor([-9.6041e-01, -1.0723e+04, -5.6952e+06], grad_fn=<CopySlices>)\n",
            "Iter:   51,   Loss: -0.9604, alpha: 0.7666, beta: 0.2650, gamma: 0.3098, kE: 119146.1094, kS: 0.7842, kI: 3097799.0000\n",
            "Iter:   51,   Loss: -10723.1416, alpha: 0.7666, beta: 0.2650, gamma: 0.3099, kE: 119146.1094, kS: 0.7854, kI: 3097799.0000\n",
            "Iter:   51,   Loss: -5695185.0000, alpha: 5958.0796, beta: 0.2650, gamma: 0.3098, kE: 154889.9844, kS: 0.7854, kI: 3097799.0000\n",
            "tensor([-9.6185e-01, -1.3940e+04, -7.4037e+06], grad_fn=<CopySlices>)\n",
            "Iter:   52,   Loss: -0.9619, alpha: 0.7666, beta: 0.2650, gamma: 0.3098, kE: 154889.9844, kS: 0.7854, kI: 4027140.0000\n",
            "Iter:   52,   Loss: -13940.0898, alpha: 0.7666, beta: 0.2650, gamma: 0.3099, kE: 154889.9844, kS: 0.7866, kI: 4027140.0000\n",
            "Iter:   52,   Loss: -7403742.5000, alpha: 7745.2739, beta: 0.2650, gamma: 0.3098, kE: 201357.0312, kS: 0.7866, kI: 4027140.0000\n",
            "tensor([-9.6329e-01, -1.8122e+04, -9.6249e+06], grad_fn=<CopySlices>)\n",
            "Iter:   53,   Loss: -0.9633, alpha: 0.7666, beta: 0.2650, gamma: 0.3098, kE: 201357.0312, kS: 0.7866, kI: 5235283.0000\n",
            "Iter:   53,   Loss: -18122.1250, alpha: 0.7666, beta: 0.2650, gamma: 0.3099, kE: 201357.0312, kS: 0.7878, kI: 5235283.0000\n",
            "Iter:   53,   Loss: -9624867.0000, alpha: 10068.6260, beta: 0.2650, gamma: 0.3098, kE: 261764.1875, kS: 0.7878, kI: 5235283.0000\n",
            "tensor([-9.6473e-01, -2.3559e+04, -1.2512e+07], grad_fn=<CopySlices>)\n",
            "Iter:   54,   Loss: -0.9647, alpha: 0.7666, beta: 0.2650, gamma: 0.3098, kE: 261764.1875, kS: 0.7878, kI: 6805869.0000\n",
            "Iter:   54,   Loss: -23558.7676, alpha: 0.7666, beta: 0.2650, gamma: 0.3099, kE: 261764.1875, kS: 0.7890, kI: 6805869.0000\n",
            "Iter:   54,   Loss: -12512329.0000, alpha: 13088.9834, beta: 0.2650, gamma: 0.3098, kE: 340293.5000, kS: 0.7890, kI: 6805869.0000\n",
            "tensor([-9.6617e-01, -3.0626e+04, -1.6266e+07], grad_fn=<CopySlices>)\n",
            "Iter:   55,   Loss: -0.9662, alpha: 0.7666, beta: 0.2650, gamma: 0.3098, kE: 340293.5000, kS: 0.7890, kI: 8847631.0000\n",
            "Iter:   55,   Loss: -30626.4062, alpha: 0.7666, beta: 0.2650, gamma: 0.3099, kE: 340293.5000, kS: 0.7902, kI: 8847631.0000\n",
            "Iter:   55,   Loss: -16266030.0000, alpha: 17015.4492, beta: 0.2650, gamma: 0.3098, kE: 442381.5938, kS: 0.7902, kI: 8847631.0000\n",
            "tensor([-9.6761e-01, -3.9814e+04, -2.1146e+07], grad_fn=<CopySlices>)\n",
            "Iter:   56,   Loss: -0.9676, alpha: 0.7676, beta: 0.2650, gamma: 0.3098, kE: 442381.5938, kS: 0.7902, kI: 11501922.0000\n",
            "Iter:   56,   Loss: -39814.3320, alpha: 0.7676, beta: 0.2650, gamma: 0.3099, kE: 442381.5938, kS: 0.7914, kI: 11501922.0000\n",
            "Iter:   56,   Loss: -21145844.0000, alpha: 22119.8535, beta: 0.2650, gamma: 0.3098, kE: 575096.1250, kS: 0.7914, kI: 11501922.0000\n",
            "tensor([-9.6905e-01, -5.1759e+04, -2.7490e+07], grad_fn=<CopySlices>)\n",
            "Iter:   57,   Loss: -0.9691, alpha: 0.7676, beta: 0.2650, gamma: 0.3098, kE: 575096.1250, kS: 0.7914, kI: 14952500.0000\n",
            "Iter:   57,   Loss: -51758.6406, alpha: 0.7676, beta: 0.2650, gamma: 0.3099, kE: 575096.1250, kS: 0.7926, kI: 14952500.0000\n",
            "Iter:   57,   Loss: -27489598.0000, alpha: 28755.5801, beta: 0.2650, gamma: 0.3098, kE: 747625.0000, kS: 0.7926, kI: 14952500.0000\n",
            "tensor([-9.7050e-01, -6.7286e+04, -3.5736e+07], grad_fn=<CopySlices>)\n",
            "Iter:   58,   Loss: -0.9705, alpha: 0.7676, beta: 0.2650, gamma: 0.3098, kE: 747625.0000, kS: 0.7926, kI: 19438252.0000\n",
            "Iter:   58,   Loss: -67286.2422, alpha: 0.7676, beta: 0.2650, gamma: 0.3099, kE: 747625.0000, kS: 0.7938, kI: 19438252.0000\n",
            "Iter:   58,   Loss: -35736480.0000, alpha: 37382.0234, beta: 0.2650, gamma: 0.3098, kE: 971912.5000, kS: 0.7938, kI: 19438252.0000\n",
            "tensor([-9.7193e-01, -8.7472e+04, -4.6457e+07], grad_fn=<CopySlices>)\n",
            "Iter:   59,   Loss: -0.9719, alpha: 0.7695, beta: 0.2650, gamma: 0.3098, kE: 971912.5000, kS: 0.7938, kI: 25269728.0000\n",
            "Iter:   59,   Loss: -87472.1172, alpha: 0.7695, beta: 0.2650, gamma: 0.3099, kE: 971912.5000, kS: 0.7950, kI: 25269728.0000\n",
            "Iter:   59,   Loss: -46457424.0000, alpha: 48596.4023, beta: 0.2650, gamma: 0.3098, kE: 1263486.2500, kS: 0.7950, kI: 25269728.0000\n",
            "tensor([-9.7338e-01, -1.1371e+05, -6.0395e+07], grad_fn=<CopySlices>)\n",
            "Iter:   60,   Loss: -0.9734, alpha: 0.7695, beta: 0.2650, gamma: 0.3098, kE: 1263486.2500, kS: 0.7950, kI: 32850648.0000\n",
            "Iter:   60,   Loss: -113713.7500, alpha: 0.7695, beta: 0.2650, gamma: 0.3099, kE: 1263486.2500, kS: 0.7962, kI: 32850648.0000\n",
            "Iter:   60,   Loss: -60394656.0000, alpha: 63175.0977, beta: 0.2650, gamma: 0.3098, kE: 1642532.2500, kS: 0.7962, kI: 32850648.0000\n",
            "tensor([-9.7482e-01, -1.4783e+05, -7.8513e+07], grad_fn=<CopySlices>)\n",
            "Iter:   61,   Loss: -0.9748, alpha: 0.7695, beta: 0.2650, gamma: 0.3098, kE: 1642532.2500, kS: 0.7962, kI: 42705844.0000\n",
            "Iter:   61,   Loss: -147827.9062, alpha: 0.7695, beta: 0.2650, gamma: 0.3099, kE: 1642532.2500, kS: 0.7974, kI: 42705844.0000\n",
            "Iter:   61,   Loss: -78513064.0000, alpha: 82127.3906, beta: 0.2650, gamma: 0.3098, kE: 2135292.0000, kS: 0.7974, kI: 42705844.0000\n",
            "tensor([-9.7626e-01, -1.9218e+05, -1.0207e+08], grad_fn=<CopySlices>)\n",
            "Iter:   62,   Loss: -0.9763, alpha: 0.7656, beta: 0.2650, gamma: 0.3098, kE: 2135292.0000, kS: 0.7974, kI: 55517600.0000\n",
            "Iter:   62,   Loss: -192176.2812, alpha: 0.7656, beta: 0.2650, gamma: 0.3099, kE: 2135292.0000, kS: 0.7986, kI: 55517600.0000\n",
            "Iter:   62,   Loss: -102066976.0000, alpha: 106765.3750, beta: 0.2650, gamma: 0.3098, kE: 2775879.7500, kS: 0.7986, kI: 55517600.0000\n",
            "tensor([-9.7770e-01, -2.4983e+05, -1.3269e+08], grad_fn=<CopySlices>)\n",
            "Iter:   63,   Loss: -0.9777, alpha: 0.7656, beta: 0.2650, gamma: 0.3098, kE: 2775879.7500, kS: 0.7986, kI: 72172880.0000\n",
            "Iter:   63,   Loss: -249829.1719, alpha: 0.7656, beta: 0.2650, gamma: 0.3099, kE: 2775879.7500, kS: 0.7998, kI: 72172880.0000\n",
            "Iter:   63,   Loss: -132687072.0000, alpha: 138794.7656, beta: 0.2650, gamma: 0.3098, kE: 3608643.7500, kS: 0.7998, kI: 72172880.0000\n",
            "tensor([-9.7914e-01, -3.2478e+05, -1.7249e+08], grad_fn=<CopySlices>)\n",
            "Iter:   64,   Loss: -0.9791, alpha: 0.7656, beta: 0.2650, gamma: 0.3098, kE: 3608643.7500, kS: 0.7998, kI: 93824744.0000\n",
            "Iter:   64,   Loss: -324777.9062, alpha: 0.7656, beta: 0.2650, gamma: 0.3099, kE: 3608643.7500, kS: 0.8010, kI: 93824744.0000\n",
            "Iter:   64,   Loss: -172493184.0000, alpha: 180432.9688, beta: 0.2650, gamma: 0.3098, kE: 4691237.0000, kS: 0.8010, kI: 93824744.0000\n",
            "tensor([-9.8058e-01, -4.2221e+05, -2.2424e+08], grad_fn=<CopySlices>)\n",
            "Iter:   65,   Loss: -0.9806, alpha: 0.7656, beta: 0.2650, gamma: 0.3098, kE: 4691237.0000, kS: 0.8010, kI: 121972168.0000\n",
            "Iter:   65,   Loss: -422211.2812, alpha: 0.7656, beta: 0.2650, gamma: 0.3099, kE: 4691237.0000, kS: 0.8022, kI: 121972168.0000\n",
            "Iter:   65,   Loss: -224241152.0000, alpha: 234562.6250, beta: 0.2650, gamma: 0.3098, kE: 6098608.0000, kS: 0.8022, kI: 121972168.0000\n",
            "tensor([-9.8202e-01, -5.4887e+05, -2.9151e+08], grad_fn=<CopySlices>)\n",
            "Iter:   66,   Loss: -0.9820, alpha: 0.7656, beta: 0.2650, gamma: 0.3098, kE: 6098608.0000, kS: 0.8022, kI: 158563824.0000\n",
            "Iter:   66,   Loss: -548874.6875, alpha: 0.7656, beta: 0.2650, gamma: 0.3099, kE: 6098608.0000, kS: 0.8034, kI: 158563824.0000\n",
            "Iter:   66,   Loss: -291513504.0000, alpha: 304931.1875, beta: 0.2650, gamma: 0.3098, kE: 7928190.5000, kS: 0.8034, kI: 158563824.0000\n",
            "tensor([-9.8346e-01, -7.1354e+05, -3.7897e+08], grad_fn=<CopySlices>)\n",
            "Iter:   67,   Loss: -0.9835, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 7928190.5000, kS: 0.8034, kI: 206132976.0000\n",
            "Iter:   67,   Loss: -713537.1250, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 7928190.5000, kS: 0.8046, kI: 206132976.0000\n",
            "Iter:   67,   Loss: -378967552.0000, alpha: 396410.3125, beta: 0.2650, gamma: 0.3098, kE: 10306648.0000, kS: 0.8046, kI: 206132976.0000\n",
            "tensor([-9.8490e-01, -9.2760e+05, -4.9266e+08], grad_fn=<CopySlices>)\n",
            "Iter:   68,   Loss: -0.9849, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 10306648.0000, kS: 0.8046, kI: 267972864.0000\n",
            "Iter:   68,   Loss: -927598.3125, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 10306648.0000, kS: 0.8058, kI: 267972864.0000\n",
            "Iter:   68,   Loss: -492657824.0000, alpha: 515333.1875, beta: 0.2650, gamma: 0.3098, kE: 13398642.0000, kS: 0.8058, kI: 267972864.0000\n",
            "tensor([-9.8634e-01, -1.2059e+06, -6.4046e+08], grad_fn=<CopySlices>)\n",
            "Iter:   69,   Loss: -0.9863, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 13398642.0000, kS: 0.8058, kI: 348364736.0000\n",
            "Iter:   69,   Loss: -1205877.8750, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 13398642.0000, kS: 0.8070, kI: 348364736.0000\n",
            "Iter:   69,   Loss: -640455232.0000, alpha: 669932.8750, beta: 0.2650, gamma: 0.3098, kE: 17418234.0000, kS: 0.8070, kI: 348364736.0000\n",
            "tensor([-9.8778e-01, -1.5676e+06, -8.3259e+08], grad_fn=<CopySlices>)\n",
            "Iter:   70,   Loss: -0.9878, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 17418234.0000, kS: 0.8070, kI: 452874176.0000\n",
            "Iter:   70,   Loss: -1567641.1250, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 17418234.0000, kS: 0.8082, kI: 452874176.0000\n",
            "Iter:   70,   Loss: -832591744.0000, alpha: 870912.5625, beta: 0.2650, gamma: 0.3098, kE: 22643704.0000, kS: 0.8082, kI: 452874176.0000\n",
            "tensor([-9.8922e-01, -2.0379e+06, -1.0824e+09], grad_fn=<CopySlices>)\n",
            "Iter:   71,   Loss: -0.9892, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 22643704.0000, kS: 0.8082, kI: 588736448.0000\n",
            "Iter:   71,   Loss: -2037933.3750, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 22643704.0000, kS: 0.8094, kI: 588736448.0000\n",
            "Iter:   71,   Loss: -1082369280.0000, alpha: 1132186.1250, beta: 0.2650, gamma: 0.3098, kE: 29436816.0000, kS: 0.8094, kI: 588736448.0000\n",
            "tensor([-9.9066e-01, -2.6493e+06, -1.4071e+09], grad_fn=<CopySlices>)\n",
            "Iter:   72,   Loss: -0.9907, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 29436816.0000, kS: 0.8094, kI: 765357376.0000\n",
            "Iter:   72,   Loss: -2649313.5000, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 29436816.0000, kS: 0.8106, kI: 765357376.0000\n",
            "Iter:   72,   Loss: -1407080192.0000, alpha: 1471841.7500, beta: 0.2650, gamma: 0.3098, kE: 38267864.0000, kS: 0.8106, kI: 765357376.0000\n",
            "tensor([-9.9210e-01, -3.4441e+06, -1.8292e+09], grad_fn=<CopySlices>)\n",
            "Iter:   73,   Loss: -0.9921, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 38267864.0000, kS: 0.8106, kI: 994964608.0000\n",
            "Iter:   73,   Loss: -3444107.7500, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 38267864.0000, kS: 0.8118, kI: 994964608.0000\n",
            "Iter:   73,   Loss: -1829204352.0000, alpha: 1913394.1250, beta: 0.2650, gamma: 0.3098, kE: 49748224.0000, kS: 0.8118, kI: 994964608.0000\n",
            "tensor([-9.9354e-01, -4.4773e+06, -2.3780e+09], grad_fn=<CopySlices>)\n",
            "Iter:   74,   Loss: -0.9935, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 49748224.0000, kS: 0.8118, kI: 1293453952.0000\n",
            "Iter:   74,   Loss: -4477340.0000, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 49748224.0000, kS: 0.8130, kI: 1293453952.0000\n",
            "Iter:   74,   Loss: -2377965568.0000, alpha: 2487412.0000, beta: 0.2650, gamma: 0.3098, kE: 64672692.0000, kS: 0.8130, kI: 1293453952.0000\n",
            "tensor([-9.9498e-01, -5.8205e+06, -3.0914e+09], grad_fn=<CopySlices>)\n",
            "Iter:   75,   Loss: -0.9950, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 64672692.0000, kS: 0.8130, kI: 1681490176.0000\n",
            "Iter:   75,   Loss: -5820542.5000, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 64672692.0000, kS: 0.8142, kI: 1681490176.0000\n",
            "Iter:   75,   Loss: -3091355392.0000, alpha: 3233635.5000, beta: 0.2650, gamma: 0.3098, kE: 84074496.0000, kS: 0.8142, kI: 1681490176.0000\n",
            "tensor([-9.9642e-01, -7.5667e+06, -4.0188e+09], grad_fn=<CopySlices>)\n",
            "Iter:   76,   Loss: -0.9964, alpha: 0.7500, beta: 0.2650, gamma: 0.3098, kE: 84074496.0000, kS: 0.8142, kI: 2185937152.0000\n",
            "Iter:   76,   Loss: -7566704.5000, alpha: 0.7500, beta: 0.2650, gamma: 0.3099, kE: 84074496.0000, kS: 0.8154, kI: 2185937152.0000\n",
            "Iter:   76,   Loss: -4018761728.0000, alpha: 4203726.0000, beta: 0.2650, gamma: 0.3098, kE: 109296848.0000, kS: 0.8154, kI: 2185937152.0000\n",
            "tensor([-9.9786e-01, -9.8367e+06, -5.2244e+09], grad_fn=<CopySlices>)\n",
            "Iter:   77,   Loss: -0.9979, alpha: 1.0000, beta: 0.2650, gamma: 0.3098, kE: 109296848.0000, kS: 0.8154, kI: 2841718272.0000\n",
            "Iter:   77,   Loss: -9836717.0000, alpha: 1.0000, beta: 0.2650, gamma: 0.3099, kE: 109296848.0000, kS: 0.8166, kI: 2841718272.0000\n",
            "Iter:   77,   Loss: -5224389632.0000, alpha: 5464844.0000, beta: 0.2650, gamma: 0.3098, kE: 142085904.0000, kS: 0.8166, kI: 2841718272.0000\n",
            "tensor([-9.9930e-01, -1.2788e+07, -6.7917e+09], grad_fn=<CopySlices>)\n",
            "Iter:   78,   Loss: -0.9993, alpha: 1.0000, beta: 0.2650, gamma: 0.3098, kE: 142085904.0000, kS: 0.8166, kI: 3694233856.0000\n",
            "Iter:   78,   Loss: -12787732.0000, alpha: 1.0000, beta: 0.2650, gamma: 0.3099, kE: 142085904.0000, kS: 0.8178, kI: 3694233856.0000\n",
            "Iter:   78,   Loss: -6791707648.0000, alpha: 7104297.0000, beta: 0.2650, gamma: 0.3098, kE: 184711680.0000, kS: 0.8178, kI: 3694233856.0000\n",
            "tensor([-1.0007e+00, -1.6624e+07, -8.8292e+09], grad_fn=<CopySlices>)\n",
            "Iter:   79,   Loss: -1.0007, alpha: 1.0000, beta: 0.2650, gamma: 0.3098, kE: 184711680.0000, kS: 0.8178, kI: 4802504192.0000\n",
            "Iter:   79,   Loss: -16624051.0000, alpha: 1.0000, beta: 0.2650, gamma: 0.3099, kE: 184711680.0000, kS: 0.8190, kI: 4802504192.0000\n",
            "Iter:   79,   Loss: -8829219840.0000, alpha: 9235586.0000, beta: 0.2650, gamma: 0.3098, kE: 240125184.0000, kS: 0.8190, kI: 4802504192.0000\n",
            "tensor([-1.0022e+00, -2.1611e+07, -1.1478e+10], grad_fn=<CopySlices>)\n",
            "Iter:   80,   Loss: -1.0022, alpha: 1.0000, beta: 0.2650, gamma: 0.3098, kE: 240125184.0000, kS: 0.8190, kI: 6243255296.0000\n",
            "Iter:   80,   Loss: -21611266.0000, alpha: 1.0000, beta: 0.2650, gamma: 0.3099, kE: 240125184.0000, kS: 0.8202, kI: 6243255296.0000\n",
            "Iter:   80,   Loss: -11477985280.0000, alpha: 12006262.0000, beta: 0.2650, gamma: 0.3098, kE: 312162752.0000, kS: 0.8202, kI: 6243255296.0000\n",
            "tensor([-1.0036e+00, -2.8095e+07, -1.4921e+10], grad_fn=<CopySlices>)\n",
            "Iter:   81,   Loss: -1.0036, alpha: 1.0000, beta: 0.2650, gamma: 0.3098, kE: 312162752.0000, kS: 0.8202, kI: 8116232192.0000\n",
            "Iter:   81,   Loss: -28094648.0000, alpha: 1.0000, beta: 0.2650, gamma: 0.3099, kE: 312162752.0000, kS: 0.8214, kI: 8116232192.0000\n",
            "Iter:   81,   Loss: -14921381888.0000, alpha: 15608140.0000, beta: 0.2650, gamma: 0.3098, kE: 405811584.0000, kS: 0.8214, kI: 8116232192.0000\n",
            "tensor([-1.0051e+00, -3.6523e+07, -1.9398e+10], grad_fn=<CopySlices>)\n",
            "Iter:   82,   Loss: -1.0051, alpha: 1.0000, beta: 0.2650, gamma: 0.3098, kE: 405811584.0000, kS: 0.8214, kI: 10551102464.0000\n",
            "Iter:   82,   Loss: -36523040.0000, alpha: 1.0000, beta: 0.2650, gamma: 0.3099, kE: 405811584.0000, kS: 0.8226, kI: 10551102464.0000\n",
            "Iter:   82,   Loss: -19397795840.0000, alpha: 20290584.0000, beta: 0.2650, gamma: 0.3098, kE: 527555072.0000, kS: 0.8226, kI: 10551102464.0000\n",
            "tensor([-1.0065e+00, -4.7480e+07, -2.5217e+10], grad_fn=<CopySlices>)\n",
            "Iter:   83,   Loss: -1.0065, alpha: 2.0000, beta: 0.2650, gamma: 0.3098, kE: 527555072.0000, kS: 0.8226, kI: 13716433920.0000\n",
            "Iter:   83,   Loss: -47479956.0000, alpha: 2.0000, beta: 0.2650, gamma: 0.3099, kE: 527555072.0000, kS: 0.8238, kI: 13716433920.0000\n",
            "Iter:   83,   Loss: -25217136640.0000, alpha: 26377760.0000, beta: 0.2650, gamma: 0.3098, kE: 685821632.0000, kS: 0.8238, kI: 13716433920.0000\n",
            "tensor([-1.0079e+00, -6.1724e+07, -3.2782e+10], grad_fn=<CopySlices>)\n",
            "Iter:   84,   Loss: -1.0079, alpha: 2.0000, beta: 0.2650, gamma: 0.3098, kE: 685821632.0000, kS: 0.8238, kI: 17831364608.0000\n",
            "Iter:   84,   Loss: -61723944.0000, alpha: 2.0000, beta: 0.2650, gamma: 0.3099, kE: 685821632.0000, kS: 0.8250, kI: 17831364608.0000\n",
            "Iter:   84,   Loss: -32782280704.0000, alpha: 34291088.0000, beta: 0.2650, gamma: 0.3098, kE: 891568128.0000, kS: 0.8250, kI: 17831364608.0000\n",
            "tensor([-1.0094e+00, -8.0241e+07, -4.2617e+10], grad_fn=<CopySlices>)\n",
            "Iter:   85,   Loss: -1.0094, alpha: 4.0000, beta: 0.2650, gamma: 0.3098, kE: 891568128.0000, kS: 0.8250, kI: 23180773376.0000\n",
            "Iter:   85,   Loss: -80241128.0000, alpha: 4.0000, beta: 0.2650, gamma: 0.3099, kE: 891568128.0000, kS: 0.8262, kI: 23180773376.0000\n",
            "Iter:   85,   Loss: -42616963072.0000, alpha: 44578412.0000, beta: 0.2650, gamma: 0.3098, kE: 1159038592.0000, kS: 0.8262, kI: 23180773376.0000\n",
            "tensor([-1.0108e+00, -1.0431e+08, -5.5402e+10], grad_fn=<CopySlices>)\n",
            "Iter:   86,   Loss: -1.0108, alpha: 4.0000, beta: 0.2650, gamma: 0.3098, kE: 1159038592.0000, kS: 0.8262, kI: 30135005184.0000\n",
            "Iter:   86,   Loss: -104313472.0000, alpha: 4.0000, beta: 0.2650, gamma: 0.3099, kE: 1159038592.0000, kS: 0.8274, kI: 30135005184.0000\n",
            "Iter:   86,   Loss: -55402045440.0000, alpha: 57951940.0000, beta: 0.2650, gamma: 0.3098, kE: 1506750208.0000, kS: 0.8274, kI: 30135005184.0000\n",
            "tensor([-1.0123e+00, -1.3561e+08, -7.2023e+10], grad_fn=<CopySlices>)\n",
            "Iter:   87,   Loss: -1.0123, alpha: 4.0000, beta: 0.2650, gamma: 0.3098, kE: 1506750208.0000, kS: 0.8274, kI: 39175507968.0000\n",
            "Iter:   87,   Loss: -135607504.0000, alpha: 4.0000, beta: 0.2650, gamma: 0.3099, kE: 1506750208.0000, kS: 0.8286, kI: 39175507968.0000\n",
            "Iter:   87,   Loss: -72022663168.0000, alpha: 75337520.0000, beta: 0.2650, gamma: 0.3098, kE: 1958775296.0000, kS: 0.8286, kI: 39175507968.0000\n",
            "tensor([-1.0137e+00, -1.7629e+08, -9.3629e+10], grad_fn=<CopySlices>)\n",
            "Iter:   88,   Loss: -1.0137, alpha: 8.0000, beta: 0.2650, gamma: 0.3098, kE: 1958775296.0000, kS: 0.8286, kI: 50928160768.0000\n",
            "Iter:   88,   Loss: -176289776.0000, alpha: 8.0000, beta: 0.2650, gamma: 0.3099, kE: 1958775296.0000, kS: 0.8298, kI: 50928160768.0000\n",
            "Iter:   88,   Loss: -93629464576.0000, alpha: 97938776.0000, beta: 0.2650, gamma: 0.3098, kE: 2546407936.0000, kS: 0.8298, kI: 50928160768.0000\n",
            "tensor([-1.0151e+00, -2.2918e+08, -1.2172e+11], grad_fn=<CopySlices>)\n",
            "Iter:   89,   Loss: -1.0151, alpha: 8.0000, beta: 0.2650, gamma: 0.3098, kE: 2546407936.0000, kS: 0.8298, kI: 66206609408.0000\n",
            "Iter:   89,   Loss: -229176704.0000, alpha: 8.0000, beta: 0.2650, gamma: 0.3099, kE: 2546407936.0000, kS: 0.8310, kI: 66206609408.0000\n",
            "Iter:   89,   Loss: -121718308864.0000, alpha: 127320408.0000, beta: 0.2650, gamma: 0.3098, kE: 3310330368.0000, kS: 0.8310, kI: 66206609408.0000\n",
            "tensor([-1.0166e+00, -2.9793e+08, -1.5823e+11], grad_fn=<CopySlices>)\n",
            "Iter:   90,   Loss: -1.0166, alpha: 8.0000, beta: 0.2650, gamma: 0.3098, kE: 3310330368.0000, kS: 0.8310, kI: 86068592640.0000\n",
            "Iter:   90,   Loss: -297929728.0000, alpha: 8.0000, beta: 0.2650, gamma: 0.3099, kE: 3310330368.0000, kS: 0.8322, kI: 86068592640.0000\n",
            "Iter:   90,   Loss: -158233804800.0000, alpha: 165516512.0000, beta: 0.2650, gamma: 0.3098, kE: 4303429632.0000, kS: 0.8322, kI: 86068592640.0000\n",
            "tensor([-1.0180e+00, -3.8731e+08, -2.0570e+11], grad_fn=<CopySlices>)\n",
            "Iter:   91,   Loss: -1.0180, alpha: 0.0000, beta: 0.2650, gamma: 0.3098, kE: 4303429632.0000, kS: 0.8322, kI: 111889170432.0000\n",
            "Iter:   91,   Loss: -387308672.0000, alpha: 0.0000, beta: 0.2650, gamma: 0.3099, kE: 4303429632.0000, kS: 0.8334, kI: 111889170432.0000\n",
            "Iter:   91,   Loss: -205703938048.0000, alpha: 215171472.0000, beta: 0.2650, gamma: 0.3098, kE: 5594458624.0000, kS: 0.8334, kI: 111889170432.0000\n",
            "tensor([-1.0195e+00, -5.0350e+08, -2.6742e+11], grad_fn=<CopySlices>)\n",
            "Iter:   92,   Loss: -1.0195, alpha: 0.0000, beta: 0.2650, gamma: 0.3098, kE: 5594458624.0000, kS: 0.8334, kI: 145455923200.0000\n",
            "Iter:   92,   Loss: -503501280.0000, alpha: 0.0000, beta: 0.2650, gamma: 0.3099, kE: 5594458624.0000, kS: 0.8346, kI: 145455923200.0000\n",
            "Iter:   92,   Loss: -267415142400.0000, alpha: 279722912.0000, beta: 0.2650, gamma: 0.3098, kE: 7272796160.0000, kS: 0.8346, kI: 145455923200.0000\n",
            "tensor([-1.0209e+00, -6.5455e+08, -3.4764e+11], grad_fn=<CopySlices>)\n",
            "Iter:   93,   Loss: -1.0209, alpha: 0.0000, beta: 0.2650, gamma: 0.3098, kE: 7272796160.0000, kS: 0.8346, kI: 189092691968.0000\n",
            "Iter:   93,   Loss: -654551616.0000, alpha: 0.0000, beta: 0.2650, gamma: 0.3099, kE: 7272796160.0000, kS: 0.8358, kI: 189092691968.0000\n",
            "Iter:   93,   Loss: -347639644160.0000, alpha: 363639776.0000, beta: 0.2650, gamma: 0.3098, kE: 9454635008.0000, kS: 0.8358, kI: 189092691968.0000\n",
            "tensor([-1.0223e+00, -8.5092e+08, -4.5193e+11], grad_fn=<CopySlices>)\n",
            "Iter:   94,   Loss: -1.0223, alpha: 0.0000, beta: 0.2650, gamma: 0.3098, kE: 9454635008.0000, kS: 0.8358, kI: 245820506112.0000\n",
            "Iter:   94,   Loss: -850917120.0000, alpha: 0.0000, beta: 0.2650, gamma: 0.3099, kE: 9454635008.0000, kS: 0.8370, kI: 245820506112.0000\n",
            "Iter:   94,   Loss: -451931602944.0000, alpha: 472731744.0000, beta: 0.2650, gamma: 0.3098, kE: 12291024896.0000, kS: 0.8370, kI: 245820506112.0000\n",
            "tensor([-1.0238e+00, -1.1062e+09, -5.8751e+11], grad_fn=<CopySlices>)\n",
            "Iter:   95,   Loss: -1.0238, alpha: 0.0000, beta: 0.2650, gamma: 0.3098, kE: 12291024896.0000, kS: 0.8370, kI: 319566643200.0000\n",
            "Iter:   95,   Loss: -1106192256.0000, alpha: 0.0000, beta: 0.2650, gamma: 0.3099, kE: 12291024896.0000, kS: 0.8382, kI: 319566643200.0000\n",
            "Iter:   95,   Loss: -587510972416.0000, alpha: 614551232.0000, beta: 0.2650, gamma: 0.3098, kE: 15978332160.0000, kS: 0.8382, kI: 319566643200.0000\n",
            "tensor([-1.0252e+00, -1.4380e+09, -7.6376e+11], grad_fn=<CopySlices>)\n",
            "Iter:   96,   Loss: -1.0252, alpha: 0.0000, beta: 0.2650, gamma: 0.3098, kE: 15978332160.0000, kS: 0.8382, kI: 415436636160.0000\n",
            "Iter:   96,   Loss: -1438049920.0000, alpha: 0.0000, beta: 0.2650, gamma: 0.3099, kE: 15978332160.0000, kS: 0.8394, kI: 415436636160.0000\n",
            "Iter:   96,   Loss: -763764277248.0000, alpha: 798916672.0000, beta: 0.2650, gamma: 0.3098, kE: 20771831808.0000, kS: 0.8394, kI: 415436636160.0000\n",
            "tensor([-1.0267e+00, -1.8695e+09, -9.9289e+11], grad_fn=<CopySlices>)\n",
            "Iter:   97,   Loss: -1.0267, alpha: 0.0000, beta: 0.2650, gamma: 0.3098, kE: 20771831808.0000, kS: 0.8394, kI: 540067627008.0000\n",
            "Iter:   97,   Loss: -1869464832.0000, alpha: 0.0000, beta: 0.2650, gamma: 0.3099, kE: 20771831808.0000, kS: 0.8406, kI: 540067627008.0000\n",
            "Iter:   97,   Loss: -992893599744.0000, alpha: 1038591680.0000, beta: 0.2650, gamma: 0.3098, kE: 27003381760.0000, kS: 0.8406, kI: 540067627008.0000\n",
            "tensor([-1.0281e+00, -2.4303e+09, -1.2908e+12], grad_fn=<CopySlices>)\n",
            "Iter:   98,   Loss: -1.0281, alpha: 0.0000, beta: 0.2650, gamma: 0.3098, kE: 27003381760.0000, kS: 0.8406, kI: 702087954432.0000\n",
            "Iter:   98,   Loss: -2430304256.0000, alpha: 0.0000, beta: 0.2650, gamma: 0.3099, kE: 27003381760.0000, kS: 0.8418, kI: 702087954432.0000\n",
            "Iter:   98,   Loss: -1290761666560.0000, alpha: 1350169344.0000, beta: 0.2650, gamma: 0.3098, kE: 35104399360.0000, kS: 0.8418, kI: 702087954432.0000\n",
            "tensor([-1.0295e+00, -3.1594e+09, -1.6780e+12], grad_fn=<CopySlices>)\n",
            "Iter:   99,   Loss: -1.0295, alpha: 0.0000, beta: 0.2650, gamma: 0.3098, kE: 35104399360.0000, kS: 0.8418, kI: 912714366976.0000\n",
            "Iter:   99,   Loss: -3159395840.0000, alpha: 0.0000, beta: 0.2650, gamma: 0.3099, kE: 35104399360.0000, kS: 0.8430, kI: 912714366976.0000\n",
            "Iter:   99,   Loss: -1677990297600.0000, alpha: 1755220096.0000, beta: 0.2650, gamma: 0.3098, kE: 45635719168.0000, kS: 0.8430, kI: 912714366976.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lDw_KKdGlI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}