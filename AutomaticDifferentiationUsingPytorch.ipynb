{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutomaticDifferentiationUsingPytorch.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/periwinklemctartins/Coronavirus--Propogation-Simulation/blob/master/AutomaticDifferentiationUsingPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO2bSPsWNlqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib           \n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Connections between Canadian Provinces\n",
        "A = torch.tensor([[1,     1,     1,     0,     0,     0,     0,     0,     1,     0,     1,     1,     1],\n",
        "                  [1,     1,     1,     0,     0,     1,     0,     0,     1,     0,     1,     1,     0],\n",
        "                  [1,     1,     1,     0,     0,     1,     0,     1,     1,     0,     1,     1,     0],\n",
        "                  [0,     0,     0,     1,     1,     0,     0,     0,     1,     1,     1,     0,     0],\n",
        "                  [0,     0,     0,     1,     1,     0,     1,     0,     1,     1,     1,     0,     0],\n",
        "                  [0,     1,     1,     0,     0,     1,     0,     1,     1,     0,     1,     1,     1],\n",
        "                  [0,     0,     0,     0,     1,     0,     1,     0,     1,     1,     1,     0,     0],\n",
        "                  [0,     0,     1,     0,     0,     1,     0,     1,     1,     0,     1,     1,     1],\n",
        "                  [1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
        "                  [0,     0,     0,     1,     1,     0,     1,     0,     1,     1,     1,     0,     0],\n",
        "                  [1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
        "                  [1,     1,     1,     0,     0,     1,     0,     1,     1,     0,     1,     1,     0],\n",
        "                  [1,     0,     0,     0,     0,     1,     0,     1,     1,     0,     1,     0,     1]]);\n",
        "\n",
        "#Number of connections each province has                  \n",
        "L = torch.tensor([[6,    -1,    -1,     0,     0,     0,     0,     0,    -1,     0,    -1,    -1,    -1], \n",
        "                  [-1,    6,    -1,     0,     0,    -1,     0,     0,    -1,     0,    -1,    -1,     0],\n",
        "                  [-1,    1,     7,     0,     0,    -1,     0,    -1,    -1,     0,    -1,    -1,     0],\n",
        "                  [0,     0,     0,     4,    -1,     0,     0,     0,    -1,    -1,    -1,     0,     0],\n",
        "                  [0,     0,     0,    -1,     5,     0,    -1,     0,    -1,    -1,    -1,     0,     0],\n",
        "                  [0,    -1,    -1,     0,     0,     7,     0,    -1,    -1,     0,    -1,    -1,    -1],\n",
        "                  [0,     0,     0,     0,    -1,     0,     4,     0,    -1,    -1,    -1,     0,     0],\n",
        "                  [0,     0,    -1,     0,     0,    -1,     0,     6,    -1,     0,    -1,    -1,    -1],\n",
        "                  [-1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    12,    -1,    -1,    -1,   -1],\n",
        "                  [0,     0,     0,    -1,    -1,     0,    -1,     0,    -1,     5,    -1,     0,     0],\n",
        "                  [-1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    12,    -1,   -1],\n",
        "                  [-1,    -1,    -1,     0,     0,    -1,     0,    -1,    -1,     0,    -1,     7,    0],\n",
        "                  [-1,     0,     0,     0,     0,    -1,     0,    -1,    -1,     0,    -1,     0,    5]]);\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Ls36tkNqqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SEImodel(theta,S,E,I):\n",
        "    alpha = theta[0]\n",
        "    beta  = theta[1]\n",
        "    gamma = theta[2]\n",
        "    mu    = theta[3]\n",
        "    kE    = theta[4]\n",
        "    kS    = theta[5]\n",
        "    kI    = theta[6]\n",
        "    \n",
        "\n",
        "    dSdt  = -kS*L[n,n]*S - beta*E*S - gamma*I*S                 # dS/dt\n",
        "    dEdt  = -kE*L[n,n]*E + beta*E*S  + gamma*I*S - alpha*E      # dE/dt\n",
        "    dIdt  = -kI*L[n,n]*I + alpha*E - mu*I                       # dI/dt\n",
        "    \n",
        "    return dSdt, dEdt, dIdt\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjBsWqAWNtIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def integrateSEI(theta,S0,E0,I0,dt,nt):\n",
        "    \n",
        "    # vectors to save the results over time\n",
        "    Sout = torch.zeros(nt+1); Sout[0] = S0\n",
        "    Eout = torch.zeros(nt+1); Eout[0] = E0\n",
        "    Iout = torch.zeros(nt+1); Iout[0] = I0\n",
        "    \n",
        "    S = S0; E = E0; I = I0\n",
        "    for i in range(nt):\n",
        "        dSdt, dEdt, dIdt = SEImodel(theta,S,E,I)\n",
        " \n",
        "\n",
        "        S += dt*dSdt\n",
        "        E += dt*dEdt\n",
        "        I += dt*dIdt\n",
        "\n",
        "        Sout[i+1] = S\n",
        "        Eout[i+1] = E\n",
        "        Iout[i+1] = I\n",
        "       \n",
        "    if I >= 0.05:\n",
        "      print(S,E,I)\n",
        "      return Sout, Eout, Iout\n",
        "       \n",
        "    return Sout, Eout, Iout\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwTfHyfHNvYK",
        "colab_type": "code",
        "outputId": "51c3bcf1-6103-43c5-d2f2-bcc6889a9a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "#BC Data as of March 22 2020\n",
        "PopulationBC = 5071000  #Census Canada\n",
        "Recovered = 0          #Deceased -> it is impossible to tell if people who have recovered have returned to being infected\n",
        "Infected = 424 - Recovered    #https://www150.statcan.gc.ca/n1/daily-quotidien/200428/dq200428a-eng.htm\n",
        "Succeptible = PopulationBC - Infected\n",
        "#Exposed -> true value is unknown -> assume 15% of those who are exposed are not sick\n",
        "\n",
        "xmin = 0; xmax = 2.5;\n",
        "ymin = 0; ymax = .01;\n",
        "\n",
        "#March 28th highest amount of new infected, data can be found here https://experience.arcgis.com/experience/a6f23959a8b14bfa989e3cda29297ded\n",
        "#Did not use data from https://www.canada.ca/en/public-health/services/diseases/2019-novel-coronavirus-infection.html because it was less precise than the provincial one shown above\n",
        "\n",
        "S0 = Succeptible/PopulationBC\n",
        "E0 = 0.014\n",
        "I0 = Infected/PopulationBC\n",
        "\n",
        "# Set the duration for the simulation\n",
        "dt = 0.05; nt = 100\n",
        "\n",
        "# We pick the parameters as follows\n",
        "alpha = .77       #rate of exposed people that get sick\n",
        "beta  = .5       #rate of interaction of exposed and susceptible\n",
        "gamma = .1       #rate of interaction infected and susceptible\n",
        "mu    = 0.015       #rate of pepole who get resistence or die\n",
        "kE    = 0.6       #Exposed people that move around\n",
        "kS    = 0.8       #Susceptible people that move around\n",
        "kI    = 0.2     #Sick people that move around (Diffusion of sick people)\n",
        "theta = torch.tensor([alpha, beta, gamma, mu, kE, kS, kI])\n",
        "\n",
        "P = ['AB', 'BC', 'MB', 'NB', 'NL', 'NT', 'NS', 'NU', 'ON', 'PE', 'QC', 'SK', 'YT']\n",
        "for n in range(1):\n",
        "\n",
        "  S, E, I = integrateSEI(theta,S0,E0,I0,dt,nt)\n",
        "\n",
        "  t = np.arange(nt+1)*dt\n",
        "  title = 'maximum of infected people % on a given day', P[1], torch.max(I).item()\n",
        "  plt.figure(1)\n",
        "  plt.title(title)\n",
        "  plt.plot(t,S,t,E,t,I)\n",
        "\n",
        "  axes = plt.gca()\n",
        "  axes.set_xlim([xmin,xmax])\n",
        "  axes.set_ylim([ymin,ymax])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiE0bJG9R_rq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ForwardEuler(alpha,beta,gamma,mu,kE,kS,kI,S0,E0,I0,dt,nt):  #Looks to be similar to integrateSEI\n",
        "    \n",
        "    S = torch.zeros(nt+1)\n",
        "    E = torch.zeros(nt+1)\n",
        "    I = torch.zeros(nt+1)\n",
        "    S[0] = S0; E[0] = E0; I[0] = I0\n",
        "    for i in range(nt):\n",
        "        F = Model(alpha,beta,gamma,mu,kE,kS,kI,S[i],E[i],I[i])\n",
        "        S[i+1] = S[i] + dt*F[0]\n",
        "        E[i+1] = E[i] + dt*F[1]\n",
        "        I[i+1] = I[i] + dt*F[2]\n",
        "        \n",
        "    return S, E, I"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_o1vVs0KXhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Model(alpha,beta,gamma,mu,kE,kS,kI,S,E,I):  #Looks to be similar to SEImodel\n",
        "    \n",
        "    F = torch.zeros(3)\n",
        "    F[0]  = -kS*L[n,n]*S - beta*E*S - gamma*I*S                 # dS/dt\n",
        "    F[1]  = -kE*L[n,n]*E + beta*E*S  + gamma*I*S - alpha*E      # dE/dt\n",
        "    F[2]  = -kI*L[n,n]*I + alpha*E - mu*I                       # dI/dt\n",
        "    \n",
        "    return F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wo_V9z6RDLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(alpha,beta,gamma,mu,kE,kS,kI,Sobs,Eobs,Iobs,dt,nt):\n",
        "    \n",
        "    Scomp, Ecomp, Icomp = ForwardEuler(alpha,beta,gamma,mu,kE,kS,kI,S0,E0,I0,dt,nt) #comp is computed from code with a chosen beta, gamma \n",
        "    phi = torch.sum((Scomp-Sobs)**2) + torch.sum((Ecomp-Eobs)**2) + torch.sum((Icomp-Iobs)**2) #if comp and obs is the same then phi goes to zero\n",
        "    \n",
        "    return phi\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOg5IddeeQyu",
        "colab_type": "code",
        "outputId": "da464f7e-fd35-4bc4-e48e-27278919bc4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(loss(alpha,beta,gamma,mu,kE,kS,kI,S0,E0,I0,dt,nt))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(95.0419)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB8wL6-PQdZn",
        "colab_type": "code",
        "outputId": "48356e6e-5d2a-444a-cadc-09436f6d01e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "t = np.arange(nt+1); t = t*dt\n",
        "\n",
        "# Add noise to the data\n",
        "ndata = S.shape\n",
        "nS = torch.randn(ndata[0])*0.02\n",
        "nE = torch.randn(ndata[0])*0.02\n",
        "nI = torch.randn(ndata[0])*0.02\n",
        "\n",
        "Sobs = S+nS; Eobs = E+nE; Iobs = I+nI  #observed plus noise\n",
        "\n",
        "# This is what we observe\n",
        "plt.plot(t,Sobs) #make noise smaller to make the curves nicer\n",
        "plt.plot(t,Eobs)\n",
        "plt.plot(t,Iobs) \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc702c632b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFJ_8hvEwgVP",
        "colab_type": "code",
        "outputId": "daf96dfc-0e80-4216-bb4b-15e11865b303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "theta"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7700, 0.5000, 0.1000, 0.0150, 0.6000, 0.8000, 0.2000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUSPEPEs2aZy",
        "colab_type": "code",
        "outputId": "e1d5d993-bcad-4b1d-dd95-f7cbbd15e8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Now we compute gradients\n",
        "x = torch.tensor(theta, requires_grad=True)\n",
        "Sg, Eg, Ig = SEImodel(x,S0,E0,I0)\n",
        "\n",
        "Sg.backward()\n",
        "Eg.backward()\n",
        "Ig.backward()\n",
        "\n",
        "grad = x.grad\n",
        "gradEg = x.grad\n",
        "gradIg = x.grad\n",
        "\n",
        "print(gradSg)\n",
        "print(gradEg)\n",
        "print(gradIg)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3613e-05, -8.4000e-02,\n",
            "        -5.9995e+00, -5.0168e-04])\n",
            "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3613e-05, -8.4000e-02,\n",
            "        -5.9995e+00, -5.0168e-04])\n",
            "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3613e-05, -8.4000e-02,\n",
            "        -5.9995e+00, -5.0168e-04])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjchXHuOtb40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(alpha,beta,gamma,mu,kE,kS,kI,S,E,I):  #Looks to be similar to SEImodel\n",
        "    \n",
        " \n",
        "      dSdt = -kS*L[1,1]*S - beta*E*S - gamma*I*S                 # dS/dt\n",
        "      #dEdt = kE*6*E + beta*E*S  + gamma*I*S - alpha*E      # dE/dt\n",
        "      #dIdt = -kI*6*I + alpha*E - mu*I                       # dI/dt\n",
        "     \n",
        "      return dSdt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujRfFGG6_Rpf",
        "colab_type": "code",
        "outputId": "2059c36f-7180-4d94-da10-9d344395205f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    alpha = torch.rand(1, requires_grad=True)\n",
        "    beta  = torch.rand(1, requires_grad=True)\n",
        "    gamma = torch.rand(1, requires_grad=True)\n",
        "    mu    = torch.rand(1, requires_grad=True)\n",
        "    kE    = torch.rand(1, requires_grad=True)\n",
        "    kS    = torch.rand(1, requires_grad=True)\n",
        "    kI    = torch.rand(1, requires_grad=True)\n",
        "\n",
        "    num_iter = 100\n",
        "    my = 0.001\n",
        "\n",
        "    theta = torch.tensor([alpha, beta, gamma, mu, kE, kS, kI])\n",
        "\n",
        "\n",
        "    for i in range(num_iter):\n",
        "\n",
        "      dSdt = f(alpha, beta, gamma, mu, kE, kS, kI,S,E,I)\n",
        "      print(dSdt)\n",
        "    \n",
        "      dSdt.backward()\n",
        "  \n",
        "      if (i < 100) or (i%100 == 0):\n",
        "        print('Iter: %4d,   Loss: %6.4f, alpha: %6.4f, beta: %6.4f, gamma: %6.4f, kE: %6.4f, kS: %6.4f, kI: %6.4f' % (i, dSdt.item(), alpha.item(), beta.item(), gamma.item(), kE.item(), kS.item(), kI.item()))\n",
        "\n",
        "      with torch.no_grad():\n",
        "        #dy_dalpha = alpha.grad\n",
        "        dy_dbeta = beta.grad\n",
        "        dy_dgamma = gamma.grad\n",
        "        #dy_dmu = mu.grad\n",
        "        #dy_dkE = kE.grad\n",
        "        dy_dkS = kS.grad\n",
        "        #dy_dkI = kI.grad\n",
        "\n",
        "        #alpha.data = alpha - my*dy_dalpha\n",
        "        beta.data   = beta - my*dy_dbeta\n",
        "        gamma.data  = gamma - my*dy_dgamma\n",
        "        #mu.data    = mu - my*dy_dmu\n",
        "        #kE.data    = kE - my*dy_dkE\n",
        "        kS.data     = kS - my*dy_dkS\n",
        "        #kI.data    = kI - my*dy_dkI\n",
        "      \n",
        "        #alpha.grad.fill_(0.0)\n",
        "        beta.grad.fill_(0.0)\n",
        "        gamma.grad.fill_(0.0)\n",
        "        #mu.grad.fill_(0.0)\n",
        "        #kE.grad.fill_(0.0)\n",
        "        kS.grad.fill_(0.0)\n",
        "        #kI.grad.fill_(0.0)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.2636], grad_fn=<SubBackward0>)\n",
            "Iter:    0,   Loss: -0.2636, alpha: 0.6163, beta: 0.7173, gamma: 0.4302, kE: 0.9495, kS: 0.1964, kI: 0.5942\n",
            "tensor([-0.2650], grad_fn=<SubBackward0>)\n",
            "Iter:    1,   Loss: -0.2650, alpha: 0.6163, beta: 0.7173, gamma: 0.4303, kE: 0.9495, kS: 0.1976, kI: 0.5942\n",
            "tensor([-0.2665], grad_fn=<SubBackward0>)\n",
            "Iter:    2,   Loss: -0.2665, alpha: 0.6163, beta: 0.7173, gamma: 0.4303, kE: 0.9495, kS: 0.1988, kI: 0.5942\n",
            "tensor([-0.2679], grad_fn=<SubBackward0>)\n",
            "Iter:    3,   Loss: -0.2679, alpha: 0.6163, beta: 0.7173, gamma: 0.4304, kE: 0.9495, kS: 0.2000, kI: 0.5942\n",
            "tensor([-0.2694], grad_fn=<SubBackward0>)\n",
            "Iter:    4,   Loss: -0.2694, alpha: 0.6163, beta: 0.7173, gamma: 0.4305, kE: 0.9495, kS: 0.2012, kI: 0.5942\n",
            "tensor([-0.2708], grad_fn=<SubBackward0>)\n",
            "Iter:    5,   Loss: -0.2708, alpha: 0.6163, beta: 0.7173, gamma: 0.4305, kE: 0.9495, kS: 0.2024, kI: 0.5942\n",
            "tensor([-0.2723], grad_fn=<SubBackward0>)\n",
            "Iter:    6,   Loss: -0.2723, alpha: 0.6163, beta: 0.7173, gamma: 0.4306, kE: 0.9495, kS: 0.2036, kI: 0.5942\n",
            "tensor([-0.2737], grad_fn=<SubBackward0>)\n",
            "Iter:    7,   Loss: -0.2737, alpha: 0.6163, beta: 0.7173, gamma: 0.4306, kE: 0.9495, kS: 0.2048, kI: 0.5942\n",
            "tensor([-0.2751], grad_fn=<SubBackward0>)\n",
            "Iter:    8,   Loss: -0.2751, alpha: 0.6163, beta: 0.7173, gamma: 0.4307, kE: 0.9495, kS: 0.2060, kI: 0.5942\n",
            "tensor([-0.2766], grad_fn=<SubBackward0>)\n",
            "Iter:    9,   Loss: -0.2766, alpha: 0.6163, beta: 0.7173, gamma: 0.4308, kE: 0.9495, kS: 0.2072, kI: 0.5942\n",
            "tensor([-0.2780], grad_fn=<SubBackward0>)\n",
            "Iter:   10,   Loss: -0.2780, alpha: 0.6163, beta: 0.7173, gamma: 0.4308, kE: 0.9495, kS: 0.2084, kI: 0.5942\n",
            "tensor([-0.2795], grad_fn=<SubBackward0>)\n",
            "Iter:   11,   Loss: -0.2795, alpha: 0.6163, beta: 0.7173, gamma: 0.4309, kE: 0.9495, kS: 0.2096, kI: 0.5942\n",
            "tensor([-0.2809], grad_fn=<SubBackward0>)\n",
            "Iter:   12,   Loss: -0.2809, alpha: 0.6163, beta: 0.7173, gamma: 0.4309, kE: 0.9495, kS: 0.2108, kI: 0.5942\n",
            "tensor([-0.2824], grad_fn=<SubBackward0>)\n",
            "Iter:   13,   Loss: -0.2824, alpha: 0.6163, beta: 0.7173, gamma: 0.4310, kE: 0.9495, kS: 0.2120, kI: 0.5942\n",
            "tensor([-0.2838], grad_fn=<SubBackward0>)\n",
            "Iter:   14,   Loss: -0.2838, alpha: 0.6163, beta: 0.7173, gamma: 0.4311, kE: 0.9495, kS: 0.2132, kI: 0.5942\n",
            "tensor([-0.2853], grad_fn=<SubBackward0>)\n",
            "Iter:   15,   Loss: -0.2853, alpha: 0.6163, beta: 0.7173, gamma: 0.4311, kE: 0.9495, kS: 0.2144, kI: 0.5942\n",
            "tensor([-0.2867], grad_fn=<SubBackward0>)\n",
            "Iter:   16,   Loss: -0.2867, alpha: 0.6163, beta: 0.7173, gamma: 0.4312, kE: 0.9495, kS: 0.2156, kI: 0.5942\n",
            "tensor([-0.2881], grad_fn=<SubBackward0>)\n",
            "Iter:   17,   Loss: -0.2881, alpha: 0.6163, beta: 0.7173, gamma: 0.4312, kE: 0.9495, kS: 0.2168, kI: 0.5942\n",
            "tensor([-0.2896], grad_fn=<SubBackward0>)\n",
            "Iter:   18,   Loss: -0.2896, alpha: 0.6163, beta: 0.7173, gamma: 0.4313, kE: 0.9495, kS: 0.2180, kI: 0.5942\n",
            "tensor([-0.2910], grad_fn=<SubBackward0>)\n",
            "Iter:   19,   Loss: -0.2910, alpha: 0.6163, beta: 0.7173, gamma: 0.4314, kE: 0.9495, kS: 0.2192, kI: 0.5942\n",
            "tensor([-0.2925], grad_fn=<SubBackward0>)\n",
            "Iter:   20,   Loss: -0.2925, alpha: 0.6163, beta: 0.7173, gamma: 0.4314, kE: 0.9495, kS: 0.2204, kI: 0.5942\n",
            "tensor([-0.2939], grad_fn=<SubBackward0>)\n",
            "Iter:   21,   Loss: -0.2939, alpha: 0.6163, beta: 0.7173, gamma: 0.4315, kE: 0.9495, kS: 0.2216, kI: 0.5942\n",
            "tensor([-0.2954], grad_fn=<SubBackward0>)\n",
            "Iter:   22,   Loss: -0.2954, alpha: 0.6163, beta: 0.7173, gamma: 0.4315, kE: 0.9495, kS: 0.2228, kI: 0.5942\n",
            "tensor([-0.2968], grad_fn=<SubBackward0>)\n",
            "Iter:   23,   Loss: -0.2968, alpha: 0.6163, beta: 0.7173, gamma: 0.4316, kE: 0.9495, kS: 0.2240, kI: 0.5942\n",
            "tensor([-0.2982], grad_fn=<SubBackward0>)\n",
            "Iter:   24,   Loss: -0.2982, alpha: 0.6163, beta: 0.7173, gamma: 0.4317, kE: 0.9495, kS: 0.2252, kI: 0.5942\n",
            "tensor([-0.2997], grad_fn=<SubBackward0>)\n",
            "Iter:   25,   Loss: -0.2997, alpha: 0.6163, beta: 0.7173, gamma: 0.4317, kE: 0.9495, kS: 0.2264, kI: 0.5942\n",
            "tensor([-0.3011], grad_fn=<SubBackward0>)\n",
            "Iter:   26,   Loss: -0.3011, alpha: 0.6163, beta: 0.7173, gamma: 0.4318, kE: 0.9495, kS: 0.2276, kI: 0.5942\n",
            "tensor([-0.3026], grad_fn=<SubBackward0>)\n",
            "Iter:   27,   Loss: -0.3026, alpha: 0.6163, beta: 0.7173, gamma: 0.4318, kE: 0.9495, kS: 0.2288, kI: 0.5942\n",
            "tensor([-0.3040], grad_fn=<SubBackward0>)\n",
            "Iter:   28,   Loss: -0.3040, alpha: 0.6163, beta: 0.7173, gamma: 0.4319, kE: 0.9495, kS: 0.2300, kI: 0.5942\n",
            "tensor([-0.3055], grad_fn=<SubBackward0>)\n",
            "Iter:   29,   Loss: -0.3055, alpha: 0.6163, beta: 0.7173, gamma: 0.4320, kE: 0.9495, kS: 0.2312, kI: 0.5942\n",
            "tensor([-0.3069], grad_fn=<SubBackward0>)\n",
            "Iter:   30,   Loss: -0.3069, alpha: 0.6163, beta: 0.7173, gamma: 0.4320, kE: 0.9495, kS: 0.2324, kI: 0.5942\n",
            "tensor([-0.3083], grad_fn=<SubBackward0>)\n",
            "Iter:   31,   Loss: -0.3083, alpha: 0.6163, beta: 0.7173, gamma: 0.4321, kE: 0.9495, kS: 0.2336, kI: 0.5942\n",
            "tensor([-0.3098], grad_fn=<SubBackward0>)\n",
            "Iter:   32,   Loss: -0.3098, alpha: 0.6163, beta: 0.7174, gamma: 0.4321, kE: 0.9495, kS: 0.2348, kI: 0.5942\n",
            "tensor([-0.3112], grad_fn=<SubBackward0>)\n",
            "Iter:   33,   Loss: -0.3112, alpha: 0.6163, beta: 0.7174, gamma: 0.4322, kE: 0.9495, kS: 0.2360, kI: 0.5942\n",
            "tensor([-0.3127], grad_fn=<SubBackward0>)\n",
            "Iter:   34,   Loss: -0.3127, alpha: 0.6163, beta: 0.7174, gamma: 0.4323, kE: 0.9495, kS: 0.2372, kI: 0.5942\n",
            "tensor([-0.3141], grad_fn=<SubBackward0>)\n",
            "Iter:   35,   Loss: -0.3141, alpha: 0.6163, beta: 0.7174, gamma: 0.4323, kE: 0.9495, kS: 0.2384, kI: 0.5942\n",
            "tensor([-0.3156], grad_fn=<SubBackward0>)\n",
            "Iter:   36,   Loss: -0.3156, alpha: 0.6163, beta: 0.7174, gamma: 0.4324, kE: 0.9495, kS: 0.2396, kI: 0.5942\n",
            "tensor([-0.3170], grad_fn=<SubBackward0>)\n",
            "Iter:   37,   Loss: -0.3170, alpha: 0.6163, beta: 0.7174, gamma: 0.4324, kE: 0.9495, kS: 0.2408, kI: 0.5942\n",
            "tensor([-0.3185], grad_fn=<SubBackward0>)\n",
            "Iter:   38,   Loss: -0.3185, alpha: 0.6163, beta: 0.7174, gamma: 0.4325, kE: 0.9495, kS: 0.2420, kI: 0.5942\n",
            "tensor([-0.3199], grad_fn=<SubBackward0>)\n",
            "Iter:   39,   Loss: -0.3199, alpha: 0.6163, beta: 0.7174, gamma: 0.4326, kE: 0.9495, kS: 0.2432, kI: 0.5942\n",
            "tensor([-0.3213], grad_fn=<SubBackward0>)\n",
            "Iter:   40,   Loss: -0.3213, alpha: 0.6163, beta: 0.7174, gamma: 0.4326, kE: 0.9495, kS: 0.2444, kI: 0.5942\n",
            "tensor([-0.3228], grad_fn=<SubBackward0>)\n",
            "Iter:   41,   Loss: -0.3228, alpha: 0.6163, beta: 0.7174, gamma: 0.4327, kE: 0.9495, kS: 0.2456, kI: 0.5942\n",
            "tensor([-0.3242], grad_fn=<SubBackward0>)\n",
            "Iter:   42,   Loss: -0.3242, alpha: 0.6163, beta: 0.7174, gamma: 0.4327, kE: 0.9495, kS: 0.2468, kI: 0.5942\n",
            "tensor([-0.3257], grad_fn=<SubBackward0>)\n",
            "Iter:   43,   Loss: -0.3257, alpha: 0.6163, beta: 0.7174, gamma: 0.4328, kE: 0.9495, kS: 0.2480, kI: 0.5942\n",
            "tensor([-0.3271], grad_fn=<SubBackward0>)\n",
            "Iter:   44,   Loss: -0.3271, alpha: 0.6163, beta: 0.7174, gamma: 0.4329, kE: 0.9495, kS: 0.2492, kI: 0.5942\n",
            "tensor([-0.3286], grad_fn=<SubBackward0>)\n",
            "Iter:   45,   Loss: -0.3286, alpha: 0.6163, beta: 0.7174, gamma: 0.4329, kE: 0.9495, kS: 0.2504, kI: 0.5942\n",
            "tensor([-0.3300], grad_fn=<SubBackward0>)\n",
            "Iter:   46,   Loss: -0.3300, alpha: 0.6163, beta: 0.7174, gamma: 0.4330, kE: 0.9495, kS: 0.2516, kI: 0.5942\n",
            "tensor([-0.3314], grad_fn=<SubBackward0>)\n",
            "Iter:   47,   Loss: -0.3314, alpha: 0.6163, beta: 0.7174, gamma: 0.4330, kE: 0.9495, kS: 0.2528, kI: 0.5942\n",
            "tensor([-0.3329], grad_fn=<SubBackward0>)\n",
            "Iter:   48,   Loss: -0.3329, alpha: 0.6163, beta: 0.7174, gamma: 0.4331, kE: 0.9495, kS: 0.2540, kI: 0.5942\n",
            "tensor([-0.3343], grad_fn=<SubBackward0>)\n",
            "Iter:   49,   Loss: -0.3343, alpha: 0.6163, beta: 0.7174, gamma: 0.4332, kE: 0.9495, kS: 0.2552, kI: 0.5942\n",
            "tensor([-0.3358], grad_fn=<SubBackward0>)\n",
            "Iter:   50,   Loss: -0.3358, alpha: 0.6163, beta: 0.7174, gamma: 0.4332, kE: 0.9495, kS: 0.2564, kI: 0.5942\n",
            "tensor([-0.3372], grad_fn=<SubBackward0>)\n",
            "Iter:   51,   Loss: -0.3372, alpha: 0.6163, beta: 0.7174, gamma: 0.4333, kE: 0.9495, kS: 0.2576, kI: 0.5942\n",
            "tensor([-0.3387], grad_fn=<SubBackward0>)\n",
            "Iter:   52,   Loss: -0.3387, alpha: 0.6163, beta: 0.7174, gamma: 0.4333, kE: 0.9495, kS: 0.2588, kI: 0.5942\n",
            "tensor([-0.3401], grad_fn=<SubBackward0>)\n",
            "Iter:   53,   Loss: -0.3401, alpha: 0.6163, beta: 0.7174, gamma: 0.4334, kE: 0.9495, kS: 0.2600, kI: 0.5942\n",
            "tensor([-0.3416], grad_fn=<SubBackward0>)\n",
            "Iter:   54,   Loss: -0.3416, alpha: 0.6163, beta: 0.7174, gamma: 0.4335, kE: 0.9495, kS: 0.2612, kI: 0.5942\n",
            "tensor([-0.3430], grad_fn=<SubBackward0>)\n",
            "Iter:   55,   Loss: -0.3430, alpha: 0.6163, beta: 0.7174, gamma: 0.4335, kE: 0.9495, kS: 0.2624, kI: 0.5942\n",
            "tensor([-0.3444], grad_fn=<SubBackward0>)\n",
            "Iter:   56,   Loss: -0.3444, alpha: 0.6163, beta: 0.7174, gamma: 0.4336, kE: 0.9495, kS: 0.2636, kI: 0.5942\n",
            "tensor([-0.3459], grad_fn=<SubBackward0>)\n",
            "Iter:   57,   Loss: -0.3459, alpha: 0.6163, beta: 0.7174, gamma: 0.4336, kE: 0.9495, kS: 0.2648, kI: 0.5942\n",
            "tensor([-0.3473], grad_fn=<SubBackward0>)\n",
            "Iter:   58,   Loss: -0.3473, alpha: 0.6163, beta: 0.7174, gamma: 0.4337, kE: 0.9495, kS: 0.2660, kI: 0.5942\n",
            "tensor([-0.3488], grad_fn=<SubBackward0>)\n",
            "Iter:   59,   Loss: -0.3488, alpha: 0.6163, beta: 0.7174, gamma: 0.4338, kE: 0.9495, kS: 0.2672, kI: 0.5942\n",
            "tensor([-0.3502], grad_fn=<SubBackward0>)\n",
            "Iter:   60,   Loss: -0.3502, alpha: 0.6163, beta: 0.7174, gamma: 0.4338, kE: 0.9495, kS: 0.2684, kI: 0.5942\n",
            "tensor([-0.3517], grad_fn=<SubBackward0>)\n",
            "Iter:   61,   Loss: -0.3517, alpha: 0.6163, beta: 0.7174, gamma: 0.4339, kE: 0.9495, kS: 0.2696, kI: 0.5942\n",
            "tensor([-0.3531], grad_fn=<SubBackward0>)\n",
            "Iter:   62,   Loss: -0.3531, alpha: 0.6163, beta: 0.7174, gamma: 0.4339, kE: 0.9495, kS: 0.2708, kI: 0.5942\n",
            "tensor([-0.3545], grad_fn=<SubBackward0>)\n",
            "Iter:   63,   Loss: -0.3545, alpha: 0.6163, beta: 0.7174, gamma: 0.4340, kE: 0.9495, kS: 0.2720, kI: 0.5942\n",
            "tensor([-0.3560], grad_fn=<SubBackward0>)\n",
            "Iter:   64,   Loss: -0.3560, alpha: 0.6163, beta: 0.7174, gamma: 0.4341, kE: 0.9495, kS: 0.2732, kI: 0.5942\n",
            "tensor([-0.3574], grad_fn=<SubBackward0>)\n",
            "Iter:   65,   Loss: -0.3574, alpha: 0.6163, beta: 0.7174, gamma: 0.4341, kE: 0.9495, kS: 0.2744, kI: 0.5942\n",
            "tensor([-0.3589], grad_fn=<SubBackward0>)\n",
            "Iter:   66,   Loss: -0.3589, alpha: 0.6163, beta: 0.7175, gamma: 0.4342, kE: 0.9495, kS: 0.2756, kI: 0.5942\n",
            "tensor([-0.3603], grad_fn=<SubBackward0>)\n",
            "Iter:   67,   Loss: -0.3603, alpha: 0.6163, beta: 0.7175, gamma: 0.4342, kE: 0.9495, kS: 0.2768, kI: 0.5942\n",
            "tensor([-0.3618], grad_fn=<SubBackward0>)\n",
            "Iter:   68,   Loss: -0.3618, alpha: 0.6163, beta: 0.7175, gamma: 0.4343, kE: 0.9495, kS: 0.2780, kI: 0.5942\n",
            "tensor([-0.3632], grad_fn=<SubBackward0>)\n",
            "Iter:   69,   Loss: -0.3632, alpha: 0.6163, beta: 0.7175, gamma: 0.4344, kE: 0.9495, kS: 0.2792, kI: 0.5942\n",
            "tensor([-0.3646], grad_fn=<SubBackward0>)\n",
            "Iter:   70,   Loss: -0.3646, alpha: 0.6163, beta: 0.7175, gamma: 0.4344, kE: 0.9495, kS: 0.2804, kI: 0.5942\n",
            "tensor([-0.3661], grad_fn=<SubBackward0>)\n",
            "Iter:   71,   Loss: -0.3661, alpha: 0.6163, beta: 0.7175, gamma: 0.4345, kE: 0.9495, kS: 0.2816, kI: 0.5942\n",
            "tensor([-0.3675], grad_fn=<SubBackward0>)\n",
            "Iter:   72,   Loss: -0.3675, alpha: 0.6163, beta: 0.7175, gamma: 0.4345, kE: 0.9495, kS: 0.2828, kI: 0.5942\n",
            "tensor([-0.3690], grad_fn=<SubBackward0>)\n",
            "Iter:   73,   Loss: -0.3690, alpha: 0.6163, beta: 0.7175, gamma: 0.4346, kE: 0.9495, kS: 0.2840, kI: 0.5942\n",
            "tensor([-0.3704], grad_fn=<SubBackward0>)\n",
            "Iter:   74,   Loss: -0.3704, alpha: 0.6163, beta: 0.7175, gamma: 0.4347, kE: 0.9495, kS: 0.2852, kI: 0.5942\n",
            "tensor([-0.3719], grad_fn=<SubBackward0>)\n",
            "Iter:   75,   Loss: -0.3719, alpha: 0.6163, beta: 0.7175, gamma: 0.4347, kE: 0.9495, kS: 0.2864, kI: 0.5942\n",
            "tensor([-0.3733], grad_fn=<SubBackward0>)\n",
            "Iter:   76,   Loss: -0.3733, alpha: 0.6163, beta: 0.7175, gamma: 0.4348, kE: 0.9495, kS: 0.2876, kI: 0.5942\n",
            "tensor([-0.3748], grad_fn=<SubBackward0>)\n",
            "Iter:   77,   Loss: -0.3748, alpha: 0.6163, beta: 0.7175, gamma: 0.4348, kE: 0.9495, kS: 0.2888, kI: 0.5942\n",
            "tensor([-0.3762], grad_fn=<SubBackward0>)\n",
            "Iter:   78,   Loss: -0.3762, alpha: 0.6163, beta: 0.7175, gamma: 0.4349, kE: 0.9495, kS: 0.2900, kI: 0.5942\n",
            "tensor([-0.3776], grad_fn=<SubBackward0>)\n",
            "Iter:   79,   Loss: -0.3776, alpha: 0.6163, beta: 0.7175, gamma: 0.4350, kE: 0.9495, kS: 0.2912, kI: 0.5942\n",
            "tensor([-0.3791], grad_fn=<SubBackward0>)\n",
            "Iter:   80,   Loss: -0.3791, alpha: 0.6163, beta: 0.7175, gamma: 0.4350, kE: 0.9495, kS: 0.2924, kI: 0.5942\n",
            "tensor([-0.3805], grad_fn=<SubBackward0>)\n",
            "Iter:   81,   Loss: -0.3805, alpha: 0.6163, beta: 0.7175, gamma: 0.4351, kE: 0.9495, kS: 0.2936, kI: 0.5942\n",
            "tensor([-0.3820], grad_fn=<SubBackward0>)\n",
            "Iter:   82,   Loss: -0.3820, alpha: 0.6163, beta: 0.7175, gamma: 0.4351, kE: 0.9495, kS: 0.2948, kI: 0.5942\n",
            "tensor([-0.3834], grad_fn=<SubBackward0>)\n",
            "Iter:   83,   Loss: -0.3834, alpha: 0.6163, beta: 0.7175, gamma: 0.4352, kE: 0.9495, kS: 0.2960, kI: 0.5942\n",
            "tensor([-0.3849], grad_fn=<SubBackward0>)\n",
            "Iter:   84,   Loss: -0.3849, alpha: 0.6163, beta: 0.7175, gamma: 0.4353, kE: 0.9495, kS: 0.2972, kI: 0.5942\n",
            "tensor([-0.3863], grad_fn=<SubBackward0>)\n",
            "Iter:   85,   Loss: -0.3863, alpha: 0.6163, beta: 0.7175, gamma: 0.4353, kE: 0.9495, kS: 0.2984, kI: 0.5942\n",
            "tensor([-0.3877], grad_fn=<SubBackward0>)\n",
            "Iter:   86,   Loss: -0.3877, alpha: 0.6163, beta: 0.7175, gamma: 0.4354, kE: 0.9495, kS: 0.2996, kI: 0.5942\n",
            "tensor([-0.3892], grad_fn=<SubBackward0>)\n",
            "Iter:   87,   Loss: -0.3892, alpha: 0.6163, beta: 0.7175, gamma: 0.4354, kE: 0.9495, kS: 0.3008, kI: 0.5942\n",
            "tensor([-0.3906], grad_fn=<SubBackward0>)\n",
            "Iter:   88,   Loss: -0.3906, alpha: 0.6163, beta: 0.7175, gamma: 0.4355, kE: 0.9495, kS: 0.3020, kI: 0.5942\n",
            "tensor([-0.3921], grad_fn=<SubBackward0>)\n",
            "Iter:   89,   Loss: -0.3921, alpha: 0.6163, beta: 0.7175, gamma: 0.4356, kE: 0.9495, kS: 0.3032, kI: 0.5942\n",
            "tensor([-0.3935], grad_fn=<SubBackward0>)\n",
            "Iter:   90,   Loss: -0.3935, alpha: 0.6163, beta: 0.7175, gamma: 0.4356, kE: 0.9495, kS: 0.3044, kI: 0.5942\n",
            "tensor([-0.3950], grad_fn=<SubBackward0>)\n",
            "Iter:   91,   Loss: -0.3950, alpha: 0.6163, beta: 0.7175, gamma: 0.4357, kE: 0.9495, kS: 0.3056, kI: 0.5942\n",
            "tensor([-0.3964], grad_fn=<SubBackward0>)\n",
            "Iter:   92,   Loss: -0.3964, alpha: 0.6163, beta: 0.7175, gamma: 0.4357, kE: 0.9495, kS: 0.3068, kI: 0.5942\n",
            "tensor([-0.3979], grad_fn=<SubBackward0>)\n",
            "Iter:   93,   Loss: -0.3979, alpha: 0.6163, beta: 0.7175, gamma: 0.4358, kE: 0.9495, kS: 0.3080, kI: 0.5942\n",
            "tensor([-0.3993], grad_fn=<SubBackward0>)\n",
            "Iter:   94,   Loss: -0.3993, alpha: 0.6163, beta: 0.7175, gamma: 0.4359, kE: 0.9495, kS: 0.3092, kI: 0.5942\n",
            "tensor([-0.4007], grad_fn=<SubBackward0>)\n",
            "Iter:   95,   Loss: -0.4007, alpha: 0.6163, beta: 0.7175, gamma: 0.4359, kE: 0.9495, kS: 0.3104, kI: 0.5942\n",
            "tensor([-0.4022], grad_fn=<SubBackward0>)\n",
            "Iter:   96,   Loss: -0.4022, alpha: 0.6163, beta: 0.7175, gamma: 0.4360, kE: 0.9495, kS: 0.3116, kI: 0.5942\n",
            "tensor([-0.4036], grad_fn=<SubBackward0>)\n",
            "Iter:   97,   Loss: -0.4036, alpha: 0.6163, beta: 0.7175, gamma: 0.4360, kE: 0.9495, kS: 0.3128, kI: 0.5942\n",
            "tensor([-0.4051], grad_fn=<SubBackward0>)\n",
            "Iter:   98,   Loss: -0.4051, alpha: 0.6163, beta: 0.7175, gamma: 0.4361, kE: 0.9495, kS: 0.3140, kI: 0.5942\n",
            "tensor([-0.4065], grad_fn=<SubBackward0>)\n",
            "Iter:   99,   Loss: -0.4065, alpha: 0.6163, beta: 0.7176, gamma: 0.4362, kE: 0.9495, kS: 0.3152, kI: 0.5942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAYynelD7JZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g(alpha,beta,gamma,mu,kE,kS,kI,S,E,I):  #Looks to be similar to SEImodel\n",
        "    \n",
        "    F = torch.zeros(3)\n",
        "    F[0]  = -kS*L[n,n]*S - beta*E*S - gamma*I*S                 # dS/dt\n",
        "    F[1]  = -kE*L[n,n]*E + beta*E*S  + gamma*I*S - alpha*E      # dE/dt\n",
        "    F[2]  = -kI*L[n,n]*I + alpha*E - mu*I                       # dI/dt\n",
        "    \n",
        "    return F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ2jr307zizv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e0fb8e2-d64c-4885-91b4-f57562b2e785"
      },
      "source": [
        "    alpha = torch.rand(1, requires_grad=True)\n",
        "    beta  = torch.rand(1, requires_grad=True)\n",
        "    gamma = torch.rand(1, requires_grad=True)\n",
        "    mu    = torch.rand(1, requires_grad=True)\n",
        "    kE    = torch.rand(1, requires_grad=True)\n",
        "    kS    = torch.rand(1, requires_grad=True)\n",
        "    kI    = torch.rand(1, requires_grad=True)\n",
        "\n",
        "    num_iter = 100\n",
        "    my = 0.001\n",
        "\n",
        "    theta = torch.tensor([alpha, beta, gamma, mu, kE, kS, kI])\n",
        "\n",
        "    S = 0.2\n",
        "    E = 0.015\n",
        "    I = 0.3\n",
        "\n",
        "    for i in range(num_iter):\n",
        "\n",
        "      y = g(alpha, beta, gamma, mu, kE, kS, kI,S,E,I)\n",
        "      print(y)\n",
        "    \n",
        "      for u in range(3):\n",
        "        y[u].backward(retain_graph=True)\n",
        "   \n",
        "        if (i < 100) or (i%100 == 0):\n",
        "          print('Iter: %4d,   Loss: %6.4f, alpha: %6.4f, beta: %6.4f, gamma: %6.4f, kE: %6.4f, kS: %6.4f, kI: %6.4f' % (i, y[u].item(), alpha.item(), beta.item(), gamma.item(), kE.item(), kS.item(), kI.item()))\n",
        "\n",
        "        with torch.no_grad():\n",
        "          dy_dalpha = alpha.grad\n",
        "          dy_dbeta = beta.grad\n",
        "          dy_dgamma = gamma.grad\n",
        "          dy_dmu = mu.grad\n",
        "          dy_dkE = kE.grad\n",
        "          dy_dkS = kS.grad\n",
        "          dy_dkI = kI.grad\n",
        "\n",
        "          alpha.data  = alpha - my*dy_dalpha\n",
        "          beta.data   = beta - my*dy_dbeta\n",
        "          gamma.data  = gamma - my*dy_dgamma\n",
        "          mu.data     = mu - my*dy_dmu\n",
        "          kE.data     = kE - my*dy_dkE\n",
        "          kS.data     = kS - my*dy_dkS\n",
        "          kI.data     = kI - my*dy_dkI\n",
        "      \n",
        "          alpha.grad.fill_(0.0)\n",
        "          beta.grad.fill_(0.0)\n",
        "          gamma.grad.fill_(0.0)\n",
        "          mu.grad.fill_(0.0)\n",
        "          kE.grad.fill_(0.0)\n",
        "          kS.grad.fill_(0.0)\n",
        "          kI.grad.fill_(0.0)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.0225,  0.0109, -0.7942], grad_fn=<CopySlices>)\n",
            "Iter:    0,   Loss: -1.0225, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3479, kS: 0.8134, kI: 0.4142\n",
            "Iter:    0,   Loss: 0.0109, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3479, kS: 0.8146, kI: 0.4142\n",
            "Iter:    0,   Loss: -0.7942, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3480, kS: 0.8146, kI: 0.4142\n",
            "tensor([-1.0239,  0.0109, -0.7975], grad_fn=<CopySlices>)\n",
            "Iter:    1,   Loss: -1.0239, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3480, kS: 0.8146, kI: 0.4160\n",
            "Iter:    1,   Loss: 0.0109, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3480, kS: 0.8158, kI: 0.4160\n",
            "Iter:    1,   Loss: -0.7975, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3481, kS: 0.8158, kI: 0.4160\n",
            "tensor([-1.0254,  0.0109, -0.8008], grad_fn=<CopySlices>)\n",
            "Iter:    2,   Loss: -1.0254, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3481, kS: 0.8158, kI: 0.4178\n",
            "Iter:    2,   Loss: 0.0109, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3481, kS: 0.8170, kI: 0.4178\n",
            "Iter:    2,   Loss: -0.8008, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3481, kS: 0.8170, kI: 0.4178\n",
            "tensor([-1.0268,  0.0109, -0.8042], grad_fn=<CopySlices>)\n",
            "Iter:    3,   Loss: -1.0268, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3481, kS: 0.8170, kI: 0.4196\n",
            "Iter:    3,   Loss: 0.0109, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3481, kS: 0.8182, kI: 0.4196\n",
            "Iter:    3,   Loss: -0.8042, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3482, kS: 0.8182, kI: 0.4196\n",
            "tensor([-1.0282,  0.0109, -0.8075], grad_fn=<CopySlices>)\n",
            "Iter:    4,   Loss: -1.0282, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3482, kS: 0.8182, kI: 0.4214\n",
            "Iter:    4,   Loss: 0.0109, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3482, kS: 0.8194, kI: 0.4214\n",
            "Iter:    4,   Loss: -0.8075, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3483, kS: 0.8194, kI: 0.4214\n",
            "tensor([-1.0297,  0.0108, -0.8108], grad_fn=<CopySlices>)\n",
            "Iter:    5,   Loss: -1.0297, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3483, kS: 0.8194, kI: 0.4232\n",
            "Iter:    5,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3483, kS: 0.8206, kI: 0.4232\n",
            "Iter:    5,   Loss: -0.8108, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3484, kS: 0.8206, kI: 0.4232\n",
            "tensor([-1.0311,  0.0108, -0.8142], grad_fn=<CopySlices>)\n",
            "Iter:    6,   Loss: -1.0311, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3484, kS: 0.8206, kI: 0.4250\n",
            "Iter:    6,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3484, kS: 0.8218, kI: 0.4250\n",
            "Iter:    6,   Loss: -0.8142, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3485, kS: 0.8218, kI: 0.4250\n",
            "tensor([-1.0326,  0.0108, -0.8175], grad_fn=<CopySlices>)\n",
            "Iter:    7,   Loss: -1.0326, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3485, kS: 0.8218, kI: 0.4268\n",
            "Iter:    7,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3485, kS: 0.8230, kI: 0.4268\n",
            "Iter:    7,   Loss: -0.8175, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3486, kS: 0.8230, kI: 0.4268\n",
            "tensor([-1.0340,  0.0108, -0.8208], grad_fn=<CopySlices>)\n",
            "Iter:    8,   Loss: -1.0340, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3486, kS: 0.8230, kI: 0.4286\n",
            "Iter:    8,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3486, kS: 0.8242, kI: 0.4286\n",
            "Iter:    8,   Loss: -0.8208, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3487, kS: 0.8242, kI: 0.4286\n",
            "tensor([-1.0354,  0.0108, -0.8241], grad_fn=<CopySlices>)\n",
            "Iter:    9,   Loss: -1.0354, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3487, kS: 0.8242, kI: 0.4304\n",
            "Iter:    9,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3487, kS: 0.8254, kI: 0.4304\n",
            "Iter:    9,   Loss: -0.8241, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3488, kS: 0.8254, kI: 0.4304\n",
            "tensor([-1.0369,  0.0108, -0.8275], grad_fn=<CopySlices>)\n",
            "Iter:   10,   Loss: -1.0369, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3488, kS: 0.8254, kI: 0.4322\n",
            "Iter:   10,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3488, kS: 0.8266, kI: 0.4322\n",
            "Iter:   10,   Loss: -0.8275, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3489, kS: 0.8266, kI: 0.4322\n",
            "tensor([-1.0383,  0.0108, -0.8308], grad_fn=<CopySlices>)\n",
            "Iter:   11,   Loss: -1.0383, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3489, kS: 0.8266, kI: 0.4340\n",
            "Iter:   11,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3489, kS: 0.8278, kI: 0.4340\n",
            "Iter:   11,   Loss: -0.8308, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3490, kS: 0.8278, kI: 0.4340\n",
            "tensor([-1.0398,  0.0108, -0.8341], grad_fn=<CopySlices>)\n",
            "Iter:   12,   Loss: -1.0398, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3490, kS: 0.8278, kI: 0.4358\n",
            "Iter:   12,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3490, kS: 0.8290, kI: 0.4358\n",
            "Iter:   12,   Loss: -0.8341, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3490, kS: 0.8290, kI: 0.4358\n",
            "tensor([-1.0412,  0.0108, -0.8375], grad_fn=<CopySlices>)\n",
            "Iter:   13,   Loss: -1.0412, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3490, kS: 0.8290, kI: 0.4376\n",
            "Iter:   13,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3490, kS: 0.8302, kI: 0.4376\n",
            "Iter:   13,   Loss: -0.8375, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3491, kS: 0.8302, kI: 0.4376\n",
            "tensor([-1.0426,  0.0108, -0.8408], grad_fn=<CopySlices>)\n",
            "Iter:   14,   Loss: -1.0426, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3491, kS: 0.8302, kI: 0.4394\n",
            "Iter:   14,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3491, kS: 0.8314, kI: 0.4394\n",
            "Iter:   14,   Loss: -0.8408, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3492, kS: 0.8314, kI: 0.4394\n",
            "tensor([-1.0441,  0.0108, -0.8441], grad_fn=<CopySlices>)\n",
            "Iter:   15,   Loss: -1.0441, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3492, kS: 0.8314, kI: 0.4412\n",
            "Iter:   15,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3492, kS: 0.8326, kI: 0.4412\n",
            "Iter:   15,   Loss: -0.8441, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3493, kS: 0.8326, kI: 0.4412\n",
            "tensor([-1.0455,  0.0108, -0.8475], grad_fn=<CopySlices>)\n",
            "Iter:   16,   Loss: -1.0455, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3493, kS: 0.8326, kI: 0.4430\n",
            "Iter:   16,   Loss: 0.0108, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3493, kS: 0.8338, kI: 0.4430\n",
            "Iter:   16,   Loss: -0.8475, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3494, kS: 0.8338, kI: 0.4430\n",
            "tensor([-1.0470,  0.0107, -0.8508], grad_fn=<CopySlices>)\n",
            "Iter:   17,   Loss: -1.0470, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3494, kS: 0.8338, kI: 0.4448\n",
            "Iter:   17,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3494, kS: 0.8350, kI: 0.4448\n",
            "Iter:   17,   Loss: -0.8508, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3495, kS: 0.8350, kI: 0.4448\n",
            "tensor([-1.0484,  0.0107, -0.8541], grad_fn=<CopySlices>)\n",
            "Iter:   18,   Loss: -1.0484, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3495, kS: 0.8350, kI: 0.4466\n",
            "Iter:   18,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3495, kS: 0.8362, kI: 0.4466\n",
            "Iter:   18,   Loss: -0.8541, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3496, kS: 0.8362, kI: 0.4466\n",
            "tensor([-1.0498,  0.0107, -0.8574], grad_fn=<CopySlices>)\n",
            "Iter:   19,   Loss: -1.0498, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3496, kS: 0.8362, kI: 0.4484\n",
            "Iter:   19,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3496, kS: 0.8374, kI: 0.4484\n",
            "Iter:   19,   Loss: -0.8574, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3497, kS: 0.8374, kI: 0.4484\n",
            "tensor([-1.0513,  0.0107, -0.8608], grad_fn=<CopySlices>)\n",
            "Iter:   20,   Loss: -1.0513, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3497, kS: 0.8374, kI: 0.4502\n",
            "Iter:   20,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3497, kS: 0.8386, kI: 0.4502\n",
            "Iter:   20,   Loss: -0.8608, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3498, kS: 0.8386, kI: 0.4502\n",
            "tensor([-1.0527,  0.0107, -0.8641], grad_fn=<CopySlices>)\n",
            "Iter:   21,   Loss: -1.0527, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3498, kS: 0.8386, kI: 0.4520\n",
            "Iter:   21,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3498, kS: 0.8398, kI: 0.4520\n",
            "Iter:   21,   Loss: -0.8641, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3499, kS: 0.8398, kI: 0.4520\n",
            "tensor([-1.0542,  0.0107, -0.8674], grad_fn=<CopySlices>)\n",
            "Iter:   22,   Loss: -1.0542, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3499, kS: 0.8398, kI: 0.4538\n",
            "Iter:   22,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3499, kS: 0.8410, kI: 0.4538\n",
            "Iter:   22,   Loss: -0.8674, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3499, kS: 0.8410, kI: 0.4538\n",
            "tensor([-1.0556,  0.0107, -0.8708], grad_fn=<CopySlices>)\n",
            "Iter:   23,   Loss: -1.0556, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3499, kS: 0.8410, kI: 0.4556\n",
            "Iter:   23,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3499, kS: 0.8422, kI: 0.4556\n",
            "Iter:   23,   Loss: -0.8708, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3500, kS: 0.8422, kI: 0.4556\n",
            "tensor([-1.0570,  0.0107, -0.8741], grad_fn=<CopySlices>)\n",
            "Iter:   24,   Loss: -1.0570, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3500, kS: 0.8422, kI: 0.4574\n",
            "Iter:   24,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3500, kS: 0.8434, kI: 0.4574\n",
            "Iter:   24,   Loss: -0.8741, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3501, kS: 0.8434, kI: 0.4574\n",
            "tensor([-1.0585,  0.0107, -0.8774], grad_fn=<CopySlices>)\n",
            "Iter:   25,   Loss: -1.0585, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3501, kS: 0.8434, kI: 0.4592\n",
            "Iter:   25,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3501, kS: 0.8446, kI: 0.4592\n",
            "Iter:   25,   Loss: -0.8774, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3502, kS: 0.8446, kI: 0.4592\n",
            "tensor([-1.0599,  0.0107, -0.8808], grad_fn=<CopySlices>)\n",
            "Iter:   26,   Loss: -1.0599, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3502, kS: 0.8446, kI: 0.4610\n",
            "Iter:   26,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3502, kS: 0.8458, kI: 0.4610\n",
            "Iter:   26,   Loss: -0.8808, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3503, kS: 0.8458, kI: 0.4610\n",
            "tensor([-1.0614,  0.0107, -0.8841], grad_fn=<CopySlices>)\n",
            "Iter:   27,   Loss: -1.0614, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3503, kS: 0.8458, kI: 0.4628\n",
            "Iter:   27,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3503, kS: 0.8470, kI: 0.4628\n",
            "Iter:   27,   Loss: -0.8841, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3504, kS: 0.8470, kI: 0.4628\n",
            "tensor([-1.0628,  0.0107, -0.8874], grad_fn=<CopySlices>)\n",
            "Iter:   28,   Loss: -1.0628, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3504, kS: 0.8470, kI: 0.4646\n",
            "Iter:   28,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3504, kS: 0.8482, kI: 0.4646\n",
            "Iter:   28,   Loss: -0.8874, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3505, kS: 0.8482, kI: 0.4646\n",
            "tensor([-1.0642,  0.0107, -0.8907], grad_fn=<CopySlices>)\n",
            "Iter:   29,   Loss: -1.0642, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3505, kS: 0.8482, kI: 0.4664\n",
            "Iter:   29,   Loss: 0.0107, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3505, kS: 0.8494, kI: 0.4664\n",
            "Iter:   29,   Loss: -0.8907, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3506, kS: 0.8494, kI: 0.4664\n",
            "tensor([-1.0657,  0.0106, -0.8941], grad_fn=<CopySlices>)\n",
            "Iter:   30,   Loss: -1.0657, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3506, kS: 0.8494, kI: 0.4682\n",
            "Iter:   30,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3506, kS: 0.8506, kI: 0.4682\n",
            "Iter:   30,   Loss: -0.8941, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3507, kS: 0.8506, kI: 0.4682\n",
            "tensor([-1.0671,  0.0106, -0.8974], grad_fn=<CopySlices>)\n",
            "Iter:   31,   Loss: -1.0671, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3507, kS: 0.8506, kI: 0.4700\n",
            "Iter:   31,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3507, kS: 0.8518, kI: 0.4700\n",
            "Iter:   31,   Loss: -0.8974, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3508, kS: 0.8518, kI: 0.4700\n",
            "tensor([-1.0686,  0.0106, -0.9007], grad_fn=<CopySlices>)\n",
            "Iter:   32,   Loss: -1.0686, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3508, kS: 0.8518, kI: 0.4718\n",
            "Iter:   32,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3508, kS: 0.8530, kI: 0.4718\n",
            "Iter:   32,   Loss: -0.9007, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3508, kS: 0.8530, kI: 0.4718\n",
            "tensor([-1.0700,  0.0106, -0.9041], grad_fn=<CopySlices>)\n",
            "Iter:   33,   Loss: -1.0700, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3508, kS: 0.8530, kI: 0.4736\n",
            "Iter:   33,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3508, kS: 0.8542, kI: 0.4736\n",
            "Iter:   33,   Loss: -0.9041, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3509, kS: 0.8542, kI: 0.4736\n",
            "tensor([-1.0714,  0.0106, -0.9074], grad_fn=<CopySlices>)\n",
            "Iter:   34,   Loss: -1.0714, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3509, kS: 0.8542, kI: 0.4754\n",
            "Iter:   34,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3509, kS: 0.8554, kI: 0.4754\n",
            "Iter:   34,   Loss: -0.9074, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3510, kS: 0.8554, kI: 0.4754\n",
            "tensor([-1.0729,  0.0106, -0.9107], grad_fn=<CopySlices>)\n",
            "Iter:   35,   Loss: -1.0729, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3510, kS: 0.8554, kI: 0.4772\n",
            "Iter:   35,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3510, kS: 0.8566, kI: 0.4772\n",
            "Iter:   35,   Loss: -0.9107, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3511, kS: 0.8566, kI: 0.4772\n",
            "tensor([-1.0743,  0.0106, -0.9141], grad_fn=<CopySlices>)\n",
            "Iter:   36,   Loss: -1.0743, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3511, kS: 0.8566, kI: 0.4790\n",
            "Iter:   36,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3511, kS: 0.8578, kI: 0.4790\n",
            "Iter:   36,   Loss: -0.9141, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3512, kS: 0.8578, kI: 0.4790\n",
            "tensor([-1.0758,  0.0106, -0.9174], grad_fn=<CopySlices>)\n",
            "Iter:   37,   Loss: -1.0758, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3512, kS: 0.8578, kI: 0.4808\n",
            "Iter:   37,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3512, kS: 0.8590, kI: 0.4808\n",
            "Iter:   37,   Loss: -0.9174, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3513, kS: 0.8590, kI: 0.4808\n",
            "tensor([-1.0772,  0.0106, -0.9207], grad_fn=<CopySlices>)\n",
            "Iter:   38,   Loss: -1.0772, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3513, kS: 0.8590, kI: 0.4826\n",
            "Iter:   38,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3513, kS: 0.8602, kI: 0.4826\n",
            "Iter:   38,   Loss: -0.9207, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3514, kS: 0.8602, kI: 0.4826\n",
            "tensor([-1.0786,  0.0106, -0.9240], grad_fn=<CopySlices>)\n",
            "Iter:   39,   Loss: -1.0786, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3514, kS: 0.8602, kI: 0.4844\n",
            "Iter:   39,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3514, kS: 0.8614, kI: 0.4844\n",
            "Iter:   39,   Loss: -0.9240, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3515, kS: 0.8614, kI: 0.4844\n",
            "tensor([-1.0801,  0.0106, -0.9274], grad_fn=<CopySlices>)\n",
            "Iter:   40,   Loss: -1.0801, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3515, kS: 0.8614, kI: 0.4862\n",
            "Iter:   40,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3515, kS: 0.8626, kI: 0.4862\n",
            "Iter:   40,   Loss: -0.9274, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3516, kS: 0.8626, kI: 0.4862\n",
            "tensor([-1.0815,  0.0106, -0.9307], grad_fn=<CopySlices>)\n",
            "Iter:   41,   Loss: -1.0815, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3516, kS: 0.8626, kI: 0.4880\n",
            "Iter:   41,   Loss: 0.0106, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3516, kS: 0.8638, kI: 0.4880\n",
            "Iter:   41,   Loss: -0.9307, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3517, kS: 0.8638, kI: 0.4880\n",
            "tensor([-1.0830,  0.0105, -0.9340], grad_fn=<CopySlices>)\n",
            "Iter:   42,   Loss: -1.0830, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3517, kS: 0.8638, kI: 0.4898\n",
            "Iter:   42,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3517, kS: 0.8650, kI: 0.4898\n",
            "Iter:   42,   Loss: -0.9340, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3517, kS: 0.8650, kI: 0.4898\n",
            "tensor([-1.0844,  0.0105, -0.9374], grad_fn=<CopySlices>)\n",
            "Iter:   43,   Loss: -1.0844, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3517, kS: 0.8650, kI: 0.4916\n",
            "Iter:   43,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3517, kS: 0.8662, kI: 0.4916\n",
            "Iter:   43,   Loss: -0.9374, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3518, kS: 0.8662, kI: 0.4916\n",
            "tensor([-1.0858,  0.0105, -0.9407], grad_fn=<CopySlices>)\n",
            "Iter:   44,   Loss: -1.0858, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3518, kS: 0.8662, kI: 0.4934\n",
            "Iter:   44,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3518, kS: 0.8674, kI: 0.4934\n",
            "Iter:   44,   Loss: -0.9407, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3519, kS: 0.8674, kI: 0.4934\n",
            "tensor([-1.0873,  0.0105, -0.9440], grad_fn=<CopySlices>)\n",
            "Iter:   45,   Loss: -1.0873, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3519, kS: 0.8674, kI: 0.4952\n",
            "Iter:   45,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3519, kS: 0.8686, kI: 0.4952\n",
            "Iter:   45,   Loss: -0.9440, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3520, kS: 0.8686, kI: 0.4952\n",
            "tensor([-1.0887,  0.0105, -0.9474], grad_fn=<CopySlices>)\n",
            "Iter:   46,   Loss: -1.0887, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3520, kS: 0.8686, kI: 0.4970\n",
            "Iter:   46,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3520, kS: 0.8698, kI: 0.4970\n",
            "Iter:   46,   Loss: -0.9474, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3521, kS: 0.8698, kI: 0.4970\n",
            "tensor([-1.0902,  0.0105, -0.9507], grad_fn=<CopySlices>)\n",
            "Iter:   47,   Loss: -1.0902, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3521, kS: 0.8698, kI: 0.4988\n",
            "Iter:   47,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3521, kS: 0.8710, kI: 0.4988\n",
            "Iter:   47,   Loss: -0.9507, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3522, kS: 0.8710, kI: 0.4988\n",
            "tensor([-1.0916,  0.0105, -0.9540], grad_fn=<CopySlices>)\n",
            "Iter:   48,   Loss: -1.0916, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3522, kS: 0.8710, kI: 0.5006\n",
            "Iter:   48,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3522, kS: 0.8722, kI: 0.5006\n",
            "Iter:   48,   Loss: -0.9540, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3523, kS: 0.8722, kI: 0.5006\n",
            "tensor([-1.0930,  0.0105, -0.9573], grad_fn=<CopySlices>)\n",
            "Iter:   49,   Loss: -1.0930, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3523, kS: 0.8722, kI: 0.5024\n",
            "Iter:   49,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3523, kS: 0.8734, kI: 0.5024\n",
            "Iter:   49,   Loss: -0.9573, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3524, kS: 0.8734, kI: 0.5024\n",
            "tensor([-1.0945,  0.0105, -0.9607], grad_fn=<CopySlices>)\n",
            "Iter:   50,   Loss: -1.0945, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3524, kS: 0.8734, kI: 0.5042\n",
            "Iter:   50,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3524, kS: 0.8746, kI: 0.5042\n",
            "Iter:   50,   Loss: -0.9607, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3525, kS: 0.8746, kI: 0.5042\n",
            "tensor([-1.0959,  0.0105, -0.9640], grad_fn=<CopySlices>)\n",
            "Iter:   51,   Loss: -1.0959, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3525, kS: 0.8746, kI: 0.5060\n",
            "Iter:   51,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3525, kS: 0.8758, kI: 0.5060\n",
            "Iter:   51,   Loss: -0.9640, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3526, kS: 0.8758, kI: 0.5060\n",
            "tensor([-1.0974,  0.0105, -0.9673], grad_fn=<CopySlices>)\n",
            "Iter:   52,   Loss: -1.0974, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3526, kS: 0.8758, kI: 0.5078\n",
            "Iter:   52,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3526, kS: 0.8770, kI: 0.5078\n",
            "Iter:   52,   Loss: -0.9673, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3526, kS: 0.8770, kI: 0.5078\n",
            "tensor([-1.0988,  0.0105, -0.9707], grad_fn=<CopySlices>)\n",
            "Iter:   53,   Loss: -1.0988, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3526, kS: 0.8770, kI: 0.5096\n",
            "Iter:   53,   Loss: 0.0105, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3526, kS: 0.8782, kI: 0.5096\n",
            "Iter:   53,   Loss: -0.9707, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3527, kS: 0.8782, kI: 0.5096\n",
            "tensor([-1.1002,  0.0104, -0.9740], grad_fn=<CopySlices>)\n",
            "Iter:   54,   Loss: -1.1002, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3527, kS: 0.8782, kI: 0.5114\n",
            "Iter:   54,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3527, kS: 0.8794, kI: 0.5114\n",
            "Iter:   54,   Loss: -0.9740, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3528, kS: 0.8794, kI: 0.5114\n",
            "tensor([-1.1017,  0.0104, -0.9773], grad_fn=<CopySlices>)\n",
            "Iter:   55,   Loss: -1.1017, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3528, kS: 0.8794, kI: 0.5132\n",
            "Iter:   55,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3528, kS: 0.8806, kI: 0.5132\n",
            "Iter:   55,   Loss: -0.9773, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3529, kS: 0.8806, kI: 0.5132\n",
            "tensor([-1.1031,  0.0104, -0.9807], grad_fn=<CopySlices>)\n",
            "Iter:   56,   Loss: -1.1031, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3529, kS: 0.8806, kI: 0.5150\n",
            "Iter:   56,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3529, kS: 0.8818, kI: 0.5150\n",
            "Iter:   56,   Loss: -0.9807, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3530, kS: 0.8818, kI: 0.5150\n",
            "tensor([-1.1046,  0.0104, -0.9840], grad_fn=<CopySlices>)\n",
            "Iter:   57,   Loss: -1.1046, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3530, kS: 0.8818, kI: 0.5168\n",
            "Iter:   57,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3530, kS: 0.8830, kI: 0.5168\n",
            "Iter:   57,   Loss: -0.9840, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3531, kS: 0.8830, kI: 0.5168\n",
            "tensor([-1.1060,  0.0104, -0.9873], grad_fn=<CopySlices>)\n",
            "Iter:   58,   Loss: -1.1060, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3531, kS: 0.8830, kI: 0.5186\n",
            "Iter:   58,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3531, kS: 0.8842, kI: 0.5186\n",
            "Iter:   58,   Loss: -0.9873, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3532, kS: 0.8842, kI: 0.5186\n",
            "tensor([-1.1074,  0.0104, -0.9906], grad_fn=<CopySlices>)\n",
            "Iter:   59,   Loss: -1.1074, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3532, kS: 0.8842, kI: 0.5204\n",
            "Iter:   59,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3532, kS: 0.8854, kI: 0.5204\n",
            "Iter:   59,   Loss: -0.9906, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3533, kS: 0.8854, kI: 0.5204\n",
            "tensor([-1.1089,  0.0104, -0.9940], grad_fn=<CopySlices>)\n",
            "Iter:   60,   Loss: -1.1089, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3533, kS: 0.8854, kI: 0.5222\n",
            "Iter:   60,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3533, kS: 0.8866, kI: 0.5222\n",
            "Iter:   60,   Loss: -0.9940, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3534, kS: 0.8866, kI: 0.5222\n",
            "tensor([-1.1103,  0.0104, -0.9973], grad_fn=<CopySlices>)\n",
            "Iter:   61,   Loss: -1.1103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3534, kS: 0.8866, kI: 0.5240\n",
            "Iter:   61,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3534, kS: 0.8878, kI: 0.5240\n",
            "Iter:   61,   Loss: -0.9973, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3535, kS: 0.8878, kI: 0.5240\n",
            "tensor([-1.1118,  0.0104, -1.0006], grad_fn=<CopySlices>)\n",
            "Iter:   62,   Loss: -1.1118, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3535, kS: 0.8878, kI: 0.5258\n",
            "Iter:   62,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3535, kS: 0.8890, kI: 0.5258\n",
            "Iter:   62,   Loss: -1.0006, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3535, kS: 0.8890, kI: 0.5258\n",
            "tensor([-1.1132,  0.0104, -1.0040], grad_fn=<CopySlices>)\n",
            "Iter:   63,   Loss: -1.1132, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3535, kS: 0.8890, kI: 0.5276\n",
            "Iter:   63,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3535, kS: 0.8902, kI: 0.5276\n",
            "Iter:   63,   Loss: -1.0040, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3536, kS: 0.8902, kI: 0.5276\n",
            "tensor([-1.1146,  0.0104, -1.0073], grad_fn=<CopySlices>)\n",
            "Iter:   64,   Loss: -1.1146, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3536, kS: 0.8902, kI: 0.5294\n",
            "Iter:   64,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3536, kS: 0.8914, kI: 0.5294\n",
            "Iter:   64,   Loss: -1.0073, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3537, kS: 0.8914, kI: 0.5294\n",
            "tensor([-1.1161,  0.0104, -1.0106], grad_fn=<CopySlices>)\n",
            "Iter:   65,   Loss: -1.1161, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3537, kS: 0.8914, kI: 0.5312\n",
            "Iter:   65,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3537, kS: 0.8926, kI: 0.5312\n",
            "Iter:   65,   Loss: -1.0106, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3538, kS: 0.8926, kI: 0.5312\n",
            "tensor([-1.1175,  0.0104, -1.0140], grad_fn=<CopySlices>)\n",
            "Iter:   66,   Loss: -1.1175, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3538, kS: 0.8926, kI: 0.5330\n",
            "Iter:   66,   Loss: 0.0104, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3538, kS: 0.8938, kI: 0.5330\n",
            "Iter:   66,   Loss: -1.0140, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3539, kS: 0.8938, kI: 0.5330\n",
            "tensor([-1.1190,  0.0103, -1.0173], grad_fn=<CopySlices>)\n",
            "Iter:   67,   Loss: -1.1190, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3539, kS: 0.8938, kI: 0.5348\n",
            "Iter:   67,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3539, kS: 0.8950, kI: 0.5348\n",
            "Iter:   67,   Loss: -1.0173, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3540, kS: 0.8950, kI: 0.5348\n",
            "tensor([-1.1204,  0.0103, -1.0206], grad_fn=<CopySlices>)\n",
            "Iter:   68,   Loss: -1.1204, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3540, kS: 0.8950, kI: 0.5366\n",
            "Iter:   68,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3540, kS: 0.8962, kI: 0.5366\n",
            "Iter:   68,   Loss: -1.0206, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3541, kS: 0.8962, kI: 0.5366\n",
            "tensor([-1.1218,  0.0103, -1.0239], grad_fn=<CopySlices>)\n",
            "Iter:   69,   Loss: -1.1218, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3541, kS: 0.8962, kI: 0.5384\n",
            "Iter:   69,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3541, kS: 0.8974, kI: 0.5384\n",
            "Iter:   69,   Loss: -1.0239, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3542, kS: 0.8974, kI: 0.5384\n",
            "tensor([-1.1233,  0.0103, -1.0273], grad_fn=<CopySlices>)\n",
            "Iter:   70,   Loss: -1.1233, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3542, kS: 0.8974, kI: 0.5402\n",
            "Iter:   70,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3542, kS: 0.8986, kI: 0.5402\n",
            "Iter:   70,   Loss: -1.0273, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3543, kS: 0.8986, kI: 0.5402\n",
            "tensor([-1.1247,  0.0103, -1.0306], grad_fn=<CopySlices>)\n",
            "Iter:   71,   Loss: -1.1247, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3543, kS: 0.8986, kI: 0.5420\n",
            "Iter:   71,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3543, kS: 0.8998, kI: 0.5420\n",
            "Iter:   71,   Loss: -1.0306, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3544, kS: 0.8998, kI: 0.5420\n",
            "tensor([-1.1262,  0.0103, -1.0339], grad_fn=<CopySlices>)\n",
            "Iter:   72,   Loss: -1.1262, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3544, kS: 0.8998, kI: 0.5438\n",
            "Iter:   72,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3544, kS: 0.9010, kI: 0.5438\n",
            "Iter:   72,   Loss: -1.0339, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3544, kS: 0.9010, kI: 0.5438\n",
            "tensor([-1.1276,  0.0103, -1.0373], grad_fn=<CopySlices>)\n",
            "Iter:   73,   Loss: -1.1276, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3544, kS: 0.9010, kI: 0.5456\n",
            "Iter:   73,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3544, kS: 0.9022, kI: 0.5456\n",
            "Iter:   73,   Loss: -1.0373, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3545, kS: 0.9022, kI: 0.5456\n",
            "tensor([-1.1290,  0.0103, -1.0406], grad_fn=<CopySlices>)\n",
            "Iter:   74,   Loss: -1.1290, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3545, kS: 0.9022, kI: 0.5474\n",
            "Iter:   74,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3545, kS: 0.9034, kI: 0.5474\n",
            "Iter:   74,   Loss: -1.0406, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3546, kS: 0.9034, kI: 0.5474\n",
            "tensor([-1.1305,  0.0103, -1.0439], grad_fn=<CopySlices>)\n",
            "Iter:   75,   Loss: -1.1305, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3546, kS: 0.9034, kI: 0.5492\n",
            "Iter:   75,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3546, kS: 0.9046, kI: 0.5492\n",
            "Iter:   75,   Loss: -1.0439, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3547, kS: 0.9046, kI: 0.5492\n",
            "tensor([-1.1319,  0.0103, -1.0473], grad_fn=<CopySlices>)\n",
            "Iter:   76,   Loss: -1.1319, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3547, kS: 0.9046, kI: 0.5510\n",
            "Iter:   76,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3547, kS: 0.9058, kI: 0.5510\n",
            "Iter:   76,   Loss: -1.0473, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3548, kS: 0.9058, kI: 0.5510\n",
            "tensor([-1.1334,  0.0103, -1.0506], grad_fn=<CopySlices>)\n",
            "Iter:   77,   Loss: -1.1334, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3548, kS: 0.9058, kI: 0.5528\n",
            "Iter:   77,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3548, kS: 0.9070, kI: 0.5528\n",
            "Iter:   77,   Loss: -1.0506, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3549, kS: 0.9070, kI: 0.5528\n",
            "tensor([-1.1348,  0.0103, -1.0539], grad_fn=<CopySlices>)\n",
            "Iter:   78,   Loss: -1.1348, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3549, kS: 0.9070, kI: 0.5546\n",
            "Iter:   78,   Loss: 0.0103, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3549, kS: 0.9082, kI: 0.5546\n",
            "Iter:   78,   Loss: -1.0539, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3550, kS: 0.9082, kI: 0.5546\n",
            "tensor([-1.1362,  0.0102, -1.0572], grad_fn=<CopySlices>)\n",
            "Iter:   79,   Loss: -1.1362, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3550, kS: 0.9082, kI: 0.5564\n",
            "Iter:   79,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3550, kS: 0.9094, kI: 0.5564\n",
            "Iter:   79,   Loss: -1.0572, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3551, kS: 0.9094, kI: 0.5564\n",
            "tensor([-1.1377,  0.0102, -1.0606], grad_fn=<CopySlices>)\n",
            "Iter:   80,   Loss: -1.1377, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3551, kS: 0.9094, kI: 0.5582\n",
            "Iter:   80,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3551, kS: 0.9106, kI: 0.5582\n",
            "Iter:   80,   Loss: -1.0606, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3552, kS: 0.9106, kI: 0.5582\n",
            "tensor([-1.1391,  0.0102, -1.0639], grad_fn=<CopySlices>)\n",
            "Iter:   81,   Loss: -1.1391, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3552, kS: 0.9106, kI: 0.5600\n",
            "Iter:   81,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3552, kS: 0.9118, kI: 0.5600\n",
            "Iter:   81,   Loss: -1.0639, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3553, kS: 0.9118, kI: 0.5600\n",
            "tensor([-1.1406,  0.0102, -1.0672], grad_fn=<CopySlices>)\n",
            "Iter:   82,   Loss: -1.1406, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3553, kS: 0.9118, kI: 0.5618\n",
            "Iter:   82,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3553, kS: 0.9130, kI: 0.5618\n",
            "Iter:   82,   Loss: -1.0672, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3553, kS: 0.9130, kI: 0.5618\n",
            "tensor([-1.1420,  0.0102, -1.0706], grad_fn=<CopySlices>)\n",
            "Iter:   83,   Loss: -1.1420, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3553, kS: 0.9130, kI: 0.5636\n",
            "Iter:   83,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3553, kS: 0.9142, kI: 0.5636\n",
            "Iter:   83,   Loss: -1.0706, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3554, kS: 0.9142, kI: 0.5636\n",
            "tensor([-1.1434,  0.0102, -1.0739], grad_fn=<CopySlices>)\n",
            "Iter:   84,   Loss: -1.1434, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3554, kS: 0.9142, kI: 0.5654\n",
            "Iter:   84,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3554, kS: 0.9154, kI: 0.5654\n",
            "Iter:   84,   Loss: -1.0739, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3555, kS: 0.9154, kI: 0.5654\n",
            "tensor([-1.1449,  0.0102, -1.0772], grad_fn=<CopySlices>)\n",
            "Iter:   85,   Loss: -1.1449, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3555, kS: 0.9154, kI: 0.5672\n",
            "Iter:   85,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3555, kS: 0.9166, kI: 0.5672\n",
            "Iter:   85,   Loss: -1.0772, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3556, kS: 0.9166, kI: 0.5672\n",
            "tensor([-1.1463,  0.0102, -1.0806], grad_fn=<CopySlices>)\n",
            "Iter:   86,   Loss: -1.1463, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3556, kS: 0.9166, kI: 0.5690\n",
            "Iter:   86,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3556, kS: 0.9178, kI: 0.5690\n",
            "Iter:   86,   Loss: -1.0806, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3557, kS: 0.9178, kI: 0.5690\n",
            "tensor([-1.1478,  0.0102, -1.0839], grad_fn=<CopySlices>)\n",
            "Iter:   87,   Loss: -1.1478, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3557, kS: 0.9178, kI: 0.5708\n",
            "Iter:   87,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3557, kS: 0.9190, kI: 0.5708\n",
            "Iter:   87,   Loss: -1.0839, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3558, kS: 0.9190, kI: 0.5708\n",
            "tensor([-1.1492,  0.0102, -1.0872], grad_fn=<CopySlices>)\n",
            "Iter:   88,   Loss: -1.1492, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3558, kS: 0.9190, kI: 0.5726\n",
            "Iter:   88,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3558, kS: 0.9202, kI: 0.5726\n",
            "Iter:   88,   Loss: -1.0872, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3559, kS: 0.9202, kI: 0.5726\n",
            "tensor([-1.1506,  0.0102, -1.0905], grad_fn=<CopySlices>)\n",
            "Iter:   89,   Loss: -1.1506, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3559, kS: 0.9202, kI: 0.5744\n",
            "Iter:   89,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3559, kS: 0.9214, kI: 0.5744\n",
            "Iter:   89,   Loss: -1.0905, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3560, kS: 0.9214, kI: 0.5744\n",
            "tensor([-1.1521,  0.0102, -1.0939], grad_fn=<CopySlices>)\n",
            "Iter:   90,   Loss: -1.1521, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3560, kS: 0.9214, kI: 0.5762\n",
            "Iter:   90,   Loss: 0.0102, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3560, kS: 0.9226, kI: 0.5762\n",
            "Iter:   90,   Loss: -1.0939, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3561, kS: 0.9226, kI: 0.5762\n",
            "tensor([-1.1535,  0.0101, -1.0972], grad_fn=<CopySlices>)\n",
            "Iter:   91,   Loss: -1.1535, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3561, kS: 0.9226, kI: 0.5780\n",
            "Iter:   91,   Loss: 0.0101, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3561, kS: 0.9238, kI: 0.5780\n",
            "Iter:   91,   Loss: -1.0972, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3562, kS: 0.9238, kI: 0.5780\n",
            "tensor([-1.1550,  0.0101, -1.1005], grad_fn=<CopySlices>)\n",
            "Iter:   92,   Loss: -1.1550, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3562, kS: 0.9238, kI: 0.5798\n",
            "Iter:   92,   Loss: 0.0101, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3562, kS: 0.9250, kI: 0.5798\n",
            "Iter:   92,   Loss: -1.1005, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3562, kS: 0.9250, kI: 0.5798\n",
            "tensor([-1.1564,  0.0101, -1.1039], grad_fn=<CopySlices>)\n",
            "Iter:   93,   Loss: -1.1564, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3562, kS: 0.9250, kI: 0.5816\n",
            "Iter:   93,   Loss: 0.0101, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3562, kS: 0.9262, kI: 0.5816\n",
            "Iter:   93,   Loss: -1.1039, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3563, kS: 0.9262, kI: 0.5816\n",
            "tensor([-1.1578,  0.0101, -1.1072], grad_fn=<CopySlices>)\n",
            "Iter:   94,   Loss: -1.1578, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3563, kS: 0.9262, kI: 0.5834\n",
            "Iter:   94,   Loss: 0.0101, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3563, kS: 0.9274, kI: 0.5834\n",
            "Iter:   94,   Loss: -1.1072, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3564, kS: 0.9274, kI: 0.5834\n",
            "tensor([-1.1593,  0.0101, -1.1105], grad_fn=<CopySlices>)\n",
            "Iter:   95,   Loss: -1.1593, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3564, kS: 0.9274, kI: 0.5852\n",
            "Iter:   95,   Loss: 0.0101, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3564, kS: 0.9286, kI: 0.5852\n",
            "Iter:   95,   Loss: -1.1105, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3565, kS: 0.9286, kI: 0.5852\n",
            "tensor([-1.1607,  0.0101, -1.1139], grad_fn=<CopySlices>)\n",
            "Iter:   96,   Loss: -1.1607, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3565, kS: 0.9286, kI: 0.5870\n",
            "Iter:   96,   Loss: 0.0101, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3565, kS: 0.9298, kI: 0.5870\n",
            "Iter:   96,   Loss: -1.1139, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3566, kS: 0.9298, kI: 0.5870\n",
            "tensor([-1.1622,  0.0101, -1.1172], grad_fn=<CopySlices>)\n",
            "Iter:   97,   Loss: -1.1622, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3566, kS: 0.9298, kI: 0.5888\n",
            "Iter:   97,   Loss: 0.0101, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3566, kS: 0.9310, kI: 0.5888\n",
            "Iter:   97,   Loss: -1.1172, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3567, kS: 0.9310, kI: 0.5888\n",
            "tensor([-1.1636,  0.0101, -1.1205], grad_fn=<CopySlices>)\n",
            "Iter:   98,   Loss: -1.1636, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3567, kS: 0.9310, kI: 0.5906\n",
            "Iter:   98,   Loss: 0.0101, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3567, kS: 0.9322, kI: 0.5906\n",
            "Iter:   98,   Loss: -1.1205, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3568, kS: 0.9322, kI: 0.5906\n",
            "tensor([-1.1650,  0.0101, -1.1238], grad_fn=<CopySlices>)\n",
            "Iter:   99,   Loss: -1.1650, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3568, kS: 0.9322, kI: 0.5924\n",
            "Iter:   99,   Loss: 0.0101, alpha: 0.2820, beta: 0.4398, gamma: 0.7518, kE: 0.3568, kS: 0.9334, kI: 0.5924\n",
            "Iter:   99,   Loss: -1.1238, alpha: 0.2821, beta: 0.4398, gamma: 0.7518, kE: 0.3569, kS: 0.9334, kI: 0.5924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lDw_KKdGlI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}